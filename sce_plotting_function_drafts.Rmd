---
title: "SCE plotting_function_drafts"
output: html_document
date: "2023-02-13"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(HDF5Array)
library(SCEPlots)
library(Seurat)
library(SingleCellExperiment)
library(DelayedArray)
library(DelayedMatrixStats)
library(tictoc)
library(rlang)
library(cowplot)
library(ggplot2)
theme_set(theme_cowplot())
library(ggsci)
library(scater)
library(viridisLite)
library(patchwork)

library(dplyr)

# Functions 
# repeat_trial: performs n calls of a function and records the time taken for each
# call. Returns the time for each run in a numeric vector.
repeat_trial <- 
  function(func, ..., n){
    time <- c()
    
    for (i in 1:n){
      cat(paste0("Trial ", i, "\r"))
      
      tic()
      suppressMessages(
        do.call(
        func,
        args = list(...)
        )
      )
      
      
      invisible(capture.output(elapsed <- toc()))
  
      time <- 
        c(time, as.numeric(elapsed$toc - elapsed$tic))
    }
    
    cat("Complete. \n")
    
    time
  }

# Testing closures for above function
# run_arb_function <- 
#   function(expr){
#     expr <- quote(expr)
#     
#     eval(expr)
#   }
```

```{r}
sobj <- 
  readRDS("../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_annotated_sig_1k_v2.Rds")
sce_3 <- loadHDF5SummarizedExperiment("../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_3/")
```

```{r}
sce <- 
  loadHDF5SummarizedExperiment("../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce/")
```


# UMAP function

The code below is based on the Seurat::DimPlot function, while leaving lower-level functions intact (for now).

The version below is written for SingleCellExperiment objects only. Later, a combined function that accepts both Seurat and SCE objects will be created.

```{r}
# User arguments ####
object <- sce
reduction <- "UMAP"
group_by <- "named_clusters"
shape_by <- NULL#"named_clusters"
split_by <- "sample"
# Test subset (1,40, 56)
cells <- NULL #c("DX_AAACCCAAGCGTATAA","DX_AACAACCGTTAGTTCG", "DX_AACCATGTCTCTATGT")
dims <- c(1, 2)
# Uses same default seed as Seurat::DimPlot to yield comparable results
seed <- 1

cols = NULL
pt_size = NULL
order = NULL
shuffle = FALSE
label = FALSE
label_size = 4
label_color = 'black'
label_box = FALSE
repel = FALSE
cells_highlight = NULL
cols_highlight = '#DE2D26'
sizes_highlight = 1
na_value = 'grey50'
ncol = NULL
combine = TRUE
raster = NULL
raster_dpi = c(512, 512)

#####
# 1. Define reduction (defaults to the first reduction stored for sce objects)
# Uses rlang %||% infix
reduction <- reduction %||% SingleCellExperiment::reducedDimNames(object)[1]
# 2. Define cells to include in plot
## Same as for seurat object ##
cells <- cells %||% BiocGenerics::colnames(object) 

# 3. Fetch dimensional reduction data from object
data <- SingleCellExperiment::reducedDims(object)[[reduction]][cells, dims]
data <- BiocGenerics::as.data.frame(data)

# 4. Fetch names of dimensions to plot
# For SCE objects, use the column names for the requested dim indices
# (there is no `Key()` method for SingleCellExperiment objects)
dim_names <- colnames(data)[dims]

# 5. Process group by selection
# There is no "ident" property for SingleCellExperiment objects, so defaults 
# will be chosen based on the first metadata column, rather than the current ident class
# Store original entry for group_by
orig_groups <- group_by

if (is.null(group_by)){
  warning("group_by is NULL. Defaulting to the first column in colData.")
  group_by <- names(colData(object))[1]
}

# 6. Bind group by metadata to the table of reduction coordinates
data <-
  cbind(
    data,
    # Subsets for selected cells, and the names of entered group_by columns
    colData(object)[cells, group_by, drop = FALSE]
    )

# 7. Define group_by variables to iterate through
group_by_cols <-
  colnames(data)[3:ncol(data)]

# 8. Convert group by columns to factors if they are not already
for (group in group_by_cols) {
  if (!is.factor(data[, group])) {
    data[, group] <- factor(data[, group])
  }
}

# 9. Add shape_by data if it exists
if (!is.null(x = shape_by)) {
  data[, shape_by] <- colData(object)[cells, shape_by, drop = TRUE]
}

# 10. Same for split_by data
if (!is.null(x = split_by)) {
  data[, split_by] <- colData(object)[cells, split_by, drop = TRUE]
}

# 11. If sufffle is TRUE, randomly shuffle cells
if (isTRUE(shuffle)) {
    set.seed(seed = seed)
    data <- data[sample(x = 1:nrow(x = data)), ]
  }

# 12. Create a plot for each group_by variable in group_by_cols
plots <- 
  lapply(
    X = group_by,
    FUN = function(group) {
      plot <- Seurat::SingleDimPlot(
        data = data[, c(dim_names, group, split_by, shape_by)],
        dims = dim_names,
        col.by = group,
        # cols: a categorical pallete in this case
        cols = cols,
        pt.size = pt_size,
        shape.by = shape_by,
        order = order,
        label = FALSE,
        # Cells to highlight
        cells.highlight = cells_highlight,
        cols.highlight = cols_highlight,
        sizes.highlight = sizes_highlight,
        na.value = na_value,
        raster = raster,
        raster.dpi = raster_dpi
      )
      if (label) {
        plot <- Seurat::LabelClusters(
          plot = plot,
          id = group,
          repel = repel,
          size = label_size,
          split.by = split_by,
          box = label_box,
          color = label_color
        )
      }
      if (!is.null(x = split_by)) {
        plot <- 
          plot + 
          Seurat:::FacetTheme() +
          ggplot2::facet_wrap(
            # rlang injection operator
            # ?`!!` for more information
            facets = vars(!!sym(x = split_by)),
            ncol = if (length(x = group_by) > 1 || is.null(x = ncol)) {
              length(x = unique(x = data[, split_by]))
            } else {
              ncol
            }
          )
      }
      plot <- if (is.null(x = orig_groups)) {
        plot + labs(title = NULL)
      } else {
        plot + CenterTitle()
      }
    }
  )
  if (!is.null(x = split_by)) {
    ncol <- 1
  }
  if (combine) {
    plots <- 
      patchwork::wrap_plots(
        plots, 
        # %iff% infix (Seurat package)
        # Uses ncol if orig.groups is not NULL, otherwise uses ncol >:(
        ncol = orig_groups %iff% ncol
        )
  }
 
plots 
#return(plots)
```

```{r}
Seurat::DimPlot(
  object = sobj,
  group.by = "named_clusters",
  split.by = "sample"
)
```

# Seurat code for DimPlot

```{r}
# Seurat code
object <- sobj
group.by <- "named_clusters"
shape.by <- "sample"
reduction <- "umap"

if (length(x = dims) != 2) {
    stop("'dims' must be a two-length vector")
  }
  # Determine reduction to use (if NULL, use default))
  # %||% infix is from rlang
  reduction <- reduction %||% DefaultDimReduc(object = object)
  # Read parameter for cells to plot (defaults to all cells)
  cells <- cells %||% colnames(x = object)
  
  # Fetch data for chosen reduction from object 
  # subset for chosen cells and dims 
  data <- Embeddings(object = object[[reduction]])[cells, dims]
  # Convert to data.frame (default is a matrix)
  data <- as.data.frame(x = data)
  # Form names for dim reduction coordinates on the x- and y- axis
  dims <- 
    paste0(
      # Use the key of the *reduction* chosen by the 
      # user (or the default reduction)
      Key(object = object[[reduction]]), 
      dims
      )
  
  # Store current ident class
  object[['ident']] <- Idents(object = object)
  # Store group by variable in `orig.groups`
  orig.groups <- group.by
  # Define the group by variable, using ident column if undefined
  group.by <- group.by %||% 'ident'
  
  # Add values of the group.by metadata variable(s) for 
  # each cell to the reduction data
  data <- 
    cbind(
      data, 
      object[[group.by]][cells, , drop = FALSE]
      )
  
  # Explicitly define group.by as the column names for each metadata variable
  # added to the reduction matrix above
  group.by <- colnames(x = data)[3:ncol(x = data)]

  # If any of the metadata columns are not factors, coerce them into factors.
  for (group in group.by) {
    if (!is.factor(x = data[, group])) {
      data[, group] <- factor(x = data[, group])
    }
  }
  
  # Add data for shape.by metadata variable if it exists
  if (!is.null(x = shape.by)) {
    data[, shape.by] <- object[[shape.by, drop = TRUE]]
  }
  
  # Same for split.by metadata variable
  if (!is.null(x = split.by)) {
    data[, split.by] <- object[[split.by, drop = TRUE]]
  }
```

# Test SCEPlots::DimPlot

```{r}
sce <- loadHDF5SummarizedExperiment(dir = hdf5Dir)

# SCE object
SCEPlots::DimPlot(
  object = sce,
  reduction = "UMAP",
  group_by = "named_clusters",
  split_by = "sample"
)
```

```{r}
sobj <- readRDS("../scExploreR_files/scExploreR/Seurat_Objects/Cancer_discovery_object/pei_cd_20221122.Rds")

SCEPlots::DimPlot(
  object = sobj,
  reduction = "umap",
  group_by = "named_clusters",
  split_by = "sample"
)
```

# Feature plots

Code from Seurat package

```{r}
object <- sobj
features <- c("BCL2", "HOXA9")

dims = c(1, 2)
cells = NULL
cols = c('lightgrey', 'blue')
# cols = if (blend) {
#   c('lightgrey', '#ff0000', '#00ff00')
# } else {
#   c('lightgrey', 'blue')
# }
pt.size = NULL
order = FALSE
# Cutoffs are NA by default
min.cutoff = NA 
max.cutoff = NA
reduction = NULL
split.by = NULL
keep.scale = "feature"
shape.by = NULL
slot = 'data'
blend = FALSE
blend.threshold = 0.5
label = FALSE
label.size = 4
label.color = "black"
repel = FALSE
ncol = NULL
coord.fixed = FALSE
by.col = TRUE
#sort.cell = NULL,
#interactive = FALSE,
combine = TRUE
raster = NULL
raster.dpi = c(512, 512)

# Check keep.scale param for valid entries
if (!(is.null(x = keep.scale)) && !(keep.scale %in% c("feature", "all"))) {
  stop("`keep.scale` must be set to either `feature`, `all`, or NULL")
}

# Set a theme to remove right-hand Y axis lines
# Also sets right-hand Y axis text label formatting
# (Convert to a function?)
no_right <- theme(
  axis.line.y.right = element_blank(),
  axis.ticks.y.right = element_blank(),
  axis.text.y.right = element_blank(),
  axis.title.y.right = element_text(
    face = "bold",
    size = 14,
    margin = margin(r = 7)
  )
)

# Get the DimReduc to use
reduction <- reduction %||% DefaultDimReduc(object = object)

if (length(x = dims) != 2 || !is.numeric(x = dims)) {
  stop("'dims' must be a two-length integer vector")
}

# If blending is enabled, verify there are exactly two features entered
if (blend && length(x = features) != 2) {
  stop("Blending feature plots only works with two features")
}

# Set color scheme for blended FeaturePlots
if (blend) {
  default.colors <- eval(expr = formals(fun = FeaturePlot)$cols)
  cols <- switch(
    EXPR = as.character(x = length(x = cols)),
    '0' = {
      warning(
        "No colors provided, using default colors",
        call. = FALSE,
        immediate. = TRUE
      )
      default.colors
    },
    '1' = {
      warning(
        "Only one color provided, assuming specified is double-negative and augmenting with default colors",
        call. = FALSE,
        immediate. = TRUE
      )
      c(cols, default.colors[2:3])
    },
    '2' = {
      warning(
        "Only two colors provided, assuming specified are for features and agumenting with '",
        default.colors[1],
        "' for double-negatives",
        call. = FALSE,
        immediate. = TRUE
      )
      c(default.colors[1], cols)
    },
    '3' = cols,
    {
      warning(
        "More than three colors provided, using only first three",
        call. = FALSE,
        immediate. = TRUE
      )
      cols[1:3]
    }
  )
}
if (blend && length(x = cols) != 3) {
  stop("Blending feature plots only works with three colors; first one for negative cells")
}

# Name the reductions
dims <- paste0(Key(object = object[[reduction]]), dims)

# Define cells to be plotted
cells <- cells %||% colnames(x = object)

# Get plotting data (gets reduction data and expression data for the
# feature(s) entered simultaneously)
data <- 
  FetchData(
    object = object,
    vars = c(dims, 'ident', features),
    cells = cells,
    slot = slot
  )

# Check presence of features/dimensions
if (ncol(x = data) < 4) {
  stop(
    "None of the requested features were found: ",
    paste(features, collapse = ', '),
    " in slot ",
    slot,
    call. = FALSE
  )
} else if (!all(dims %in% colnames(x = data))) {
  stop("The dimensions requested were not found", call. = FALSE)
}

# Define feature names using the data matrix
features <- colnames(x = data)[4:ncol(x = data)]

# Determine cutoffs
min.cutoff <- mapply(
  FUN = function(cutoff, feature) {
    print("Cutoff")
    print(cutoff)
    print("feature")
    print(feature)
    
    return(ifelse(
      # For each feature and cutoff, if the cutoff is NULL, use the minimum
      # expression value for the feature. Otherwise, use the supplied
      # cutoff (percentile)
      test = is.na(x = cutoff),
      yes = min(data[, feature]),
      no = cutoff
    ))
  },
  cutoff = min.cutoff,
  feature = features
)

max.cutoff <- mapply(
  FUN = function(cutoff, feature) {
    return(ifelse(
      test = is.na(x = cutoff),
      yes = max(data[, feature]),
      no = cutoff
    ))
  },
  cutoff = max.cutoff,
  feature = features
)

  # Ensure the number of values entered for min.cutoff and max.cutoff equals the
  # number of features
  check.lengths <- unique(x = vapply(
    X = list(features, min.cutoff, max.cutoff),
    FUN = length,
    FUN.VALUE = numeric(length = 1)
  ))
  if (length(x = check.lengths) != 1) {
    stop("There must be the same number of minimum and maximum cuttoffs as there are features")
  }

  # brewer.gran: (appears to apply if an R Color Brewer palette is passed to
  # cols.
  brewer.gran <- ifelse(
    test = length(x = cols) == 1,
    yes = brewer.pal.info[cols, ]$maxcolors,
    no = length(x = cols)
  )

  # Apply cutoffs to data
  data[, 4:ncol(x = data)] <-
    sapply(
      X = 4:ncol(x = data),
      FUN = function(index) {
        data.feature <- as.vector(x = data[, index])
        min.use <-
          Seurat::SetQuantile(cutoff = min.cutoff[index - 3], data.feature)
        max.use <-
          Seurat::SetQuantile(cutoff = max.cutoff[index - 3], data.feature)
        data.feature[data.feature < min.use] <- min.use
        data.feature[data.feature > max.use] <- max.use
        if (brewer.gran == 2) {
          return(data.feature)
        }
        data.cut <- if (all(data.feature == 0)) {
          0
        }
        else {
          as.numeric(x = as.factor(x = cut(
            x = as.numeric(x = data.feature),
            breaks = brewer.gran
          )))
        }
        return(data.cut)
      }
    )
  colnames(x = data)[4:ncol(x = data)] <- features
  rownames(x = data) <- cells

  # Figure out splits (FeatureHeatmap)
  data$split <- if (is.null(x = split.by)) {
    Seurat::RandomName()
  } else {
    switch(
      EXPR = split.by,
      ident = Idents(object = object)[cells, drop = TRUE],
      object[[split.by, drop = TRUE]][cells, drop = TRUE]
    )
  }
  if (!is.factor(x = data$split)) {
    data$split <- factor(x = data$split)
  }
  # Set shaping variable
  if (!is.null(x = shape.by)) {
    data[, shape.by] <- object[[shape.by, drop = TRUE]]
  }
  # Make list of plots
  plots <- vector(
    mode = "list",
    length = ifelse(
      test = blend,
      yes = 4,
      no = length(x = features) * length(x = levels(x = data$split))
    )
  )
  # Apply common limits
  xlims <- c(floor(x = min(data[, dims[1]])), ceiling(x = max(data[, dims[1]])))
  ylims <- c(floor(min(data[, dims[2]])), ceiling(x = max(data[, dims[2]])))
  # Set blended colors
  if (blend) {
    ncol <- 4
    color.matrix <- BlendMatrix(
      two.colors = cols[2:3],
      col.threshold = blend.threshold,
      negative.color = cols[1]
    )
    cols <- cols[2:3]
    colors <- list(
      color.matrix[, 1],
      color.matrix[1, ],
      as.vector(x = color.matrix)
    )
  }
```

## Create version of `FetchData()` for SCE objects

#### Wednesday, February 15th, 2023

FetchData can pull information from both reductions and assays. For now, the SCE equivalent will only pull information from assays (summarized experiments).

NOTE: this is the initial version. For the current draft of the code, see the chunk labeled "FetchData method"

```{r}
# feature_data()
features <- c("ADT_CD90", "ADT_CD3", "RNA_HOXA9") #c("RNA_HOXA9") 
object <- sce
slot <- "logcounts"

feature_data <- function(object, features, cells = NULL, slot = NULL){
  # 1. Set default values
  # Slot (assay): defaults to the first assay stored in the object
  slot <- slot %||% assayNames(object)[1]
  # Cells: if NULL, use all cells in the object
  cells <- cells %||% colnames(object)
  
  # 2. For each feature, fetch data from object for the defined slot
  sapply(
    features,
    function(feature, object, slot){
      # 2.1. Determine the experiment "key" of the feature passed 
      # alphanumeric features to the left of an underscore will be treated as 
      # the key, and will be compared against the main and alternate experiment
      # names.
      exp <- 
        gsub(
          pattern = '(^[[:alnum:]]+)_.*', 
          replacement = "\\1", 
          x = feature, 
          fixed = FALSE
          )
      
      feature_name <- 
        gsub(
          pattern = '^[[:alnum:]]+_(.*)', 
          replacement = "\\1", 
          x = feature, 
          fixed = FALSE
          )
      
      # 2.2. Fetch data for feature from matrix
      # Determine if feature is in the main experiment or an alternate experiment
      if (exp == mainExpName(object)){
        # Determine if the feature name is in the expression matrix under 
        # the defined slot
        if (feature_name %in% rownames(assays(object)[[slot]])){
          # Pull feature row and transpose to column
          assays(object)[[slot]][feature_name, , drop = FALSE] |> 
            as.data.frame() |> 
            t()
        } else {
          # Display message to user if not found
          warning(
            glue::glue(
              "Feature {feature_name} not found in the experiment {mainExpName(object)}."
              )
            )
        }
      } else if (exp %in% altExpNames(object)){
        # Load alternate experiment (also a SingleCellExperiment object)
        alt_exp_data <- altExps(object)[[exp]]
        
        # Determine if the feature name is in the expression matrix under 
        # the defined slot
        if (feature_name %in% rownames(assays(alt_exp_data)[[slot]])){
          assays(alt_exp_data)[[slot]][feature_name, , drop = FALSE] |> 
            as.data.frame() |> 
            t()
        } else {
          # Display message to user if not found
          warning(
            glue::glue(
              "Feature {feature_name} not found in the experiment {mainExpName(alt_exp_data)}."
              )
            )
        }
      } else {
        warning(glue::glue("No experiment found matching the entered key {exp}_ (for {feature})."))
      }
    },
    object,
    slot
  )
}

feature_data(
  object = object,
  features = c("ADT_CD90", "RNA_HOXA9"),
  slot = "logcounts"
  ) |> head()


# What if a feature is entered without a prefix?
feature <- "HOXA9"
exp <- 
  gsub(
    pattern = '(^[[:alnum:]]+)_.*', 
    replacement = "\\1", 
    x = feature, 
    fixed = FALSE
    )

feature_name <- 
  gsub(
    pattern = '^[[:alnum:]]+_(.*)', 
    replacement = "\\1", 
    x = feature, 
    fixed = FALSE
    )
# If this happens, the function mistakenly assumes "HOXA9" is the assay 
# A function is required to test if the feature name passed is in "assay_feature"
# format
grepl("^[[:alnum:]]+_[[:alnum:]]+", "HOXA9")
grepl("^[[:alnum:]]+_[[:alnum:]]+", "RNA_HOXA9")
```

```{r}
output <- 
  SCEPlots::feature_data(
    object = sce,
    features = c("HOXA9", "CD90", "ADT_CD90", "ADT_CD1000")
  )
```

# Seurat::FetchData Code from SeuratObject package

Code is annotated at each major step.

```{r Seurat::FetchData Demo}
object <- sobj
cells <- NULL
# List of test variables
vars <-
  # Keyed features
  c("adt_CD117", 
    "adt_CD11b",
    "rna_HOXA9", 
    # Nonexistent features
    "adt_CD900",
    # Metadata
    "nCount_RNA", 
    "nFeature_RNA", 
    # "Ambiguous" feature not in RNA assay
    "CD90",
    "CD56",
    "CD3")
slot <- "data"

# Seurat FetchData function
object <- UpdateSlots(object = object)
cells <- cells %||% colnames(x = object)
if (is.numeric(x = cells)) {
  cells <- colnames(x = object)[cells]
}
if (is.null(x = vars)) {
  df <- EmptyDF(n = length(x = cells))
  rownames(x = df) <- cells
  return(df)
}

# Get a list of all objects to search through and their keys
# object.keys includes keys for each assay and projection
object.keys <- Key(object = object)
# Find all vars that are keyed
# at this stage, keyed.vars will be the indexes of requested features that map 
# to each *key* in the object (each *assay or reduction*). If a key does not 
# have any variables mapped to it it will be an integer of length zero.
keyed.vars <- lapply(
  X = object.keys,
  FUN = function(key) {
    if (length(x = key) == 0 || nchar(x = key) == 0) {
      return(integer(length = 0L))
    }
    return(grep(pattern = paste0('^', key), x = vars))
  }
)

keyed.vars <- Filter(f = length, x = keyed.vars)

# Determine if features requested are part of spatial transcriptomics assays
ret.spatial2 <- 
  vapply(
    X = names(x = keyed.vars),
    FUN = function(x) {
      return(inherits(x = object[[x]], what = 'FOV'))
    },
    FUN.VALUE = logical(length = 1L)
  )

if (any(ret.spatial2) && !all(ret.spatial2)) {
  warning(
    "Data returned from spatial coordinates are incompatible with other data, returning only spatial coordinates",
    call. = FALSE,
    immediate. = TRUE
  )
  keyed.vars <- keyed.vars[ret.spatial2]
}

# Generate list of data from variables mapped to keys
# Data structure returned is a list of lists
data.fetched <- lapply(
  # This iterates through each assay/reuction
  X = names(x = keyed.vars),
  FUN = function(x) {
    vars.use <- vars[keyed.vars[[x]]]
    key.use <- object.keys[x]
    # Get data for each var in the current assay
    data.return <- 
      # Procedure for fetching data depends on the class of the current assay/reduction
      if (inherits(x = object[[x]], what = 'DimReduc')) {
        tryCatch(
          expr = FetchData(object = object[[x]], vars = vars.use, cells = cells),
          error = function(e) {
            return(NULL)
          }
        )
    } else if (inherits(x = object[[x]], what = 'Assay')) {
      vars.use <- gsub(pattern = paste0('^', key.use), replacement = '', x = vars.use)
      data.assay <- GetAssayData(
        object = object,
        slot = slot,
        assay = x
      )
      
      print("Class of data_assay")
      print(class(data.assay))
      # Check to see if vars in vars.use are in the rownames of the assay first
      # (this keeps errors from occurring when vars that are not features from 
      # this assay start with what appears to be the assay key, for example 
      # if there is a metadata variable named 'rna_mitochondrial_percentage"
      # and an RNA assay)
      vars.use <- vars.use[vars.use %in% rownames(x = data.assay)]
      data.vars <- t(x = as.matrix(data.assay[vars.use, cells, drop = FALSE]))
      
      print("data.vars after fetching variables")
      print(str(data.vars))
      print(class(data.vars))
      if (ncol(data.vars) > 0) {
        colnames(x = data.vars) <- paste0(key.use, vars.use)
      }
      data.vars
    } else if (inherits(x = object[[x]], what = 'FOV')) {
      vars.use <- gsub(pattern = paste0('^', key.use), replacement = '', x = vars.use)
      FetchData(object = object[[x]], vars = vars.use, cells = cells)
    } else if (inherits(x = object[[x]], what = 'SpatialImage')) {
      vars.unkeyed <- gsub(pattern = paste0('^', key.use), replacement = '', x = vars.use)
      names(x = vars.use) <- vars.unkeyed
      coords <- GetTissueCoordinates(object = object[[x]])[cells, vars.unkeyed, drop = FALSE]
      colnames(x = coords) <- vars.use[colnames(x = coords)]
      coords
    }
    
    data.return <- as.list(x = as.data.frame(x = data.return))
    return(data.return)
  }
)

print("Before unlisting")
print(str(data.fetched))
# Removes the main list structure, but retains the list of expression values 
# returned for each variable found (via recursive = FALSE)
data.fetched <-
  unlist(x = data.fetched, recursive = FALSE)
  
print("After unlisting")
print(str(data.fetched))

if (any(ret.spatial2)) {
  return(as.data.frame(x = data.fetched))
}

# Pull vars from object metadata
# Identify metadata variables
# Test if variables that have not already been fetched are metadata variables
meta.vars <- 
  vars[vars %in% colnames(x = object[[]]) & !(vars %in% names(x = data.fetched))]

# Add metadata variables requested to the list of data fetched
# Data.frame extracted will be coerced to a list
print("Class of object with metdata variables selected")
print(class(object[[meta.vars]]))
print("Class of data.fetched")
print(class(data.fetched))
data.fetched <- c(data.fetched, object[[meta.vars]][cells, , drop = FALSE])

# Check if any metadata variables entered are also in the default assay
# (possible source of ambiguity)
meta.default <- 
  meta.vars[meta.vars %in% rownames(x = GetAssayData(object = object, slot = slot))]
if (length(x = meta.default)) {
  warning(
    "The following variables were found in both object metadata and the default assay: ",
    paste0(meta.default, collapse = ", "),
    "\nReturning metadata; if you want the feature, please use the assay's key (eg. ",
    paste0(Key(object = object[[DefaultAssay(object = object)]]), meta.default[1]),
    ")",
    call. = FALSE
  )
}

# Pull vars that are in the default assay, and are not already fetched
default.vars <- 
  vars[vars %in% rownames(x = GetAssayData(object = object, slot = slot)) & !(vars %in% names(x = data.fetched))]

# Attempt to subset the matrix for `slot` in the default assay for the variable
data.fetched <- c(
  data.fetched,
  tryCatch(
    expr = 
      as.data.frame(
        x = 
          t(
            x = as.matrix(
              x = GetAssayData(
                object = object,
                slot = slot
                )[default.vars, cells, drop = FALSE]
              )
            )
        ),
    error = function(...) {
      # If the variable is not present in the matrix, an error will be returned.
      # Return NULL in this case, which will leave data.fetched unchanged.
      return(NULL)
    }
  )
)

# Pull identities if "ident" is passed to `vars`
if ('ident' %in% vars && !'ident' %in% colnames(x = object[[]])) {
  data.fetched[['ident']] <- Idents(object = object)[cells]
}

# Try to find ambiguous vars (those not yet found with above methods)
fetched <- names(x = data.fetched)
vars.missing <- setdiff(x = vars, y = fetched)

if (length(x = vars.missing) > 0) {
  # Search in alternative assays for variables not found in the main assay
  # or metadata
  # vars.alt: an empty list with a length equal to the number of variables not 
  # yet found
  vars.alt <- vector(mode = 'list', length = length(x = vars.missing))
  names(x = vars.alt) <- vars.missing
  
  # Loop constructs a list of the assays each remaining feature was found in
  for (assay in FilterObjects(object = object, classes.keep = 'Assay')) {
    cat(paste0("Assay:", assay, "\n"))
    # Store which features from vars.missing are in the current assay
    vars.assay <- Filter(
      f = function(x) {
        features.assay <- 
          rownames(
            x = GetAssayData(
              object = object,
              assay = assay,
              slot = slot
              )
            )
        return(x %in% features.assay)
      },
      x = vars.missing
    )
    
    print("vars.assay")
    print(vars.assay)
    
    # For each variable found in this assay, append the assay name to the
    # feature's entry in vars.alt.
    for (var in vars.assay) {
      vars.alt[[var]] <- 
        append(x = vars.alt[[var]], values = assay)
    }
  }
  
  print("vars.alt")
  print(vars.alt)
  
  # Message for variables found in multiple alternative assays
  vars.many <- names(x = Filter(
    f = function(x) {
      # (Those with more than one assay entry in the list) 
      return(length(x = x) > 1)
    },
    x = vars.alt
  ))
  if (length(x = vars.many) > 0) {
    warning(
      "Found the following features in more than one assay, excluding the default. We will not include these in the final data frame: ",
      paste(vars.many, collapse = ', '),
      call. = FALSE,
      immediate. = TRUE
    )
  }
  
  # Store variables that have not been found in any assays
  vars.missing <- names(x = Filter(
    f = function(x) {
      return(length(x = x) != 1)
    },
    x = vars.alt
  ))
  
  # Pull vars found in only one alternative assay and return message
  vars.alt <- Filter(
    f = function(x) {
      return(length(x = x) == 1)
    },
    x = vars.alt
  )
  
  for (var in names(x = vars.alt)) {
    assay <- vars.alt[[var]]
    warning(
      'Could not find ',
      var,
      ' in the default search locations, found in ',
      assay,
      ' assay instead',
      immediate. = TRUE,
      call. = FALSE
    )
    keyed.var <- paste0(Key(object = object[[assay]]), var)
    data.fetched[[keyed.var]] <- as.vector(
      x = GetAssayData(object = object, assay = assay, slot = slot)[var, cells]
    )
    vars <- sub(
      pattern = paste0('^', var, '$'),
      replacement = keyed.var,
      x = vars
    )
  }
  fetched <- names(x = data.fetched)
}

# Name the vars not found in a warning (or error if none of the vars 
# entered were found)
m2 <- if (length(x = vars.missing) > 10) {
  paste0(' (10 out of ', length(x = vars.missing), ' shown)')
} else {
  ''
}
if (length(x = vars.missing) == length(x = vars)) {
  stop(
    "None of the requested variables were found",
    m2,
    ': ',
    paste(head(x = vars.missing, n = 10L), collapse = ', ')
  )
} else if (length(x = vars.missing) > 0) {
  warning(
    "The following requested variables were not found",
    m2,
    ': ',
    paste(head(x = vars.missing, n = 10L), collapse = ', ')
  )
}

# Assembled fetched vars in a data frame
data.fetched <- as.data.frame(
  x = data.fetched,
  row.names = cells,
  stringsAsFactors = FALSE
)

print("Fetched data")
#print(head(data.fetched))
print(colnames(data.fetched))

# Order data to return in the same order it was entered in vars, instead of the
# order the data was fetched.
data.order <- 
  na.omit(
    object = 
      pmatch(
        x = vars,
        # `fetched`: vector of variables for which data was found
        table = fetched
        )
    )

print("data.order")
print(data.order)

if (length(x = data.order) > 1) {
  data.fetched <- data.fetched[, data.order]
}

print("Fetched data after ordering")
#print(head(data.fetched))
print(colnames(data.fetched))

# Add column names to data.frame 
colnames(x = data.fetched) <- vars[vars %in% fetched]
return(data.fetched)
```

# Code for FetchData Method

Thursday, February 16th Monday, February 21st Thursday, March 9th, 2023

Revisiting function code to handle features not found.

```{r Fetchdata Method}
object <- sce
# Test set
vars <-
  # Keyed features
  c("ADT_CD117",
    "RNA_HOXA9",
    # Nonexistent features
    "ADT_CD900",
    "RNA_mito_pct",
    # Metadata
    "nCount_RNA",
    "nFeature_RNA",
    # Feature in RNA assay/experiment specified without a key
    "HDAC5",
    # "Ambiguous" feature not in RNA assay
    "CD90", 
    "CD56", 
    "CD3")
slot = "logcounts"
cells = NULL


# 1. Set default values
# Slot (assay): defaults to the first assay stored in the object
slot <- slot %||% assayNames(object)[1]
# Cells: if NULL, use all cells in the object
cells <- cells %||% colnames(object)

# 2. Identify which experiments have keyed features requested for them
# Experiments will be looped through, instead of looping through each var to
# find an associated experiment

# Get a list of all experiment "keys" in the object
exp_names <- c(mainExpName(object), altExpNames(object))

# Construct a list of experiments with the indices of vars that match
# each experiment
keyed_vars <-
  lapply(
    exp_names,
    function(exp){
      # grep returns the indices of matching vars
      grep(pattern = paste0('^', exp), x = vars)
    }
  )

names(keyed_vars) <- exp_names

# Subset list for experiments that have at least one matching var
keyed_vars <-
  Filter(
    # Filter list for elements with any length
    f = length,
    x = keyed_vars
  )

# 3. Loop through experiment and get data for the keyed vars in that experiment
fetched_data <-
  lapply(
    names(keyed_vars),
    function(exp){
      # Variables in current experiment
      exp_vars <- vars[keyed_vars[[exp]]]

      # Remove experiment key for feature retrieval
      keyless_vars <-
        gsub(
          pattern = paste0('^', exp, '_(.*)'),
          replacement = "\\1",
          x = exp_vars,
          fixed = FALSE
        )

      # Retrieve data
      if (exp == mainExpName(object)){
        # For main experiment
        # Subset to variables that are included in the experiment, to avoid errors
        keyless_vars <- keyless_vars[keyless_vars %in% rownames(object)]
        data <-
          assays(object)[[slot]][keyless_vars, cells, drop = FALSE] |>
          # Must be a matrix for feature names to properly display as names in
          # the final list
          # (begins as a DelayedArray)
          as.matrix() |>
          t()

        # Add experiment key back in
        colnames(data) <- paste0(exp, "_", keyless_vars)
      } else {
        # For alternate experimnent(s)
        # Switch to SingleCellExperiment object for the alternate experiment
        alt_sce <- altExps(object)[[exp]]

        keyless_vars <- keyless_vars[keyless_vars %in% rownames(alt_sce)]

        data <-
          assays(alt_sce)[[slot]][keyless_vars, cells, drop = FALSE] |>
          as.matrix() |>
          t()

        print("as.list on data")
        print(str(data))
        print(str(as.list(as.data.frame(data))))

        # Add experiment key back in
        colnames(data) <- paste0(exp, "_", keyless_vars)
      }

      # Return as a list
      data <- as.list(as.data.frame(data))
      data
    }
  )

# Nested list is returned, condense to a list (only unlist at the top level)
fetched_data <- unlist(fetched_data, recursive = FALSE)

str(fetched_data)

# 4. Fetch metadata variables
# Identify metadata variables
remaining_vars <- vars[!vars %in% names(fetched_data)]
metadata_vars <- remaining_vars[remaining_vars %in% names(colData(object))]

# Fetch metadata vars and append to fetched_data
fetched_data <-
  c(
    fetched_data,
    # SeuratObjects return metadata as a data.frame by default. This must be
    # done manually to properly append to fetched_data (data.frames can be
    # coerced to a list)
    as.data.frame(colData(object))[cells, metadata_vars, drop = FALSE]
  )

# Handle ambiguous case of metadata variables also existing in the
# main experiment (warn users that only metadata will be returned)
ambiguous_meta_vars <- metadata_vars[metadata_vars %in% rownames(object)]
if (length(ambiguous_meta_vars) > 0){
  warning(
    "The following variables were found in both object metadata and the main experiment: ",
    paste0(ambiguous_meta_vars, collapse = ", "),
    '\nOnly the metadata will be returned. To get feature data from the main experiment, please add the "key" of the main experiment to the feature (eg. ',
    paste0(mainExpName(object), "_", ambiguous_meta_vars[1]),
    ")",
    call. = FALSE
  )
}

# 5. Fetch data for vars in the main experiment that were not specified
# with an assay key
remaining_vars <- vars[!vars %in% names(fetched_data)]
main_exp_vars <- remaining_vars[remaining_vars %in% rownames(object)]

# Pull vars from main experiment
main_exp_data <-
  assays(object)[[slot]][main_exp_vars, cells, drop = FALSE] |>
  as.matrix() |>
  t()

# Explicitly specify feature names as column names
colnames(main_exp_data) <- main_exp_vars

main_exp_data <-
  main_exp_data |>
  as.data.frame() |>
  as.list()

# Append data to the list of fetched data
fetched_data <-
  c(
    fetched_data,
    main_exp_data
  )

# 6. Handle variables that have not yet been fetched
missing_vars <- vars[!vars %in% names(fetched_data)]

if (length(missing_vars) > 0){
  # 6.1. Create a list to store the experiment(s) each missing feature is in
  # Empty list for storing data
  where_missing_vars <- vector(mode = 'list', length = length(missing_vars))
  names(where_missing_vars) <- missing_vars

  for (exp in altExpNames(object)){
    alt_sce <- altExps(object)[[exp]]

    # Determine which of the missing vars are in the current exp., if any
    missing_in_exp <-
      missing_vars[missing_vars %in% rownames(assays(alt_sce)[[slot]])]

    # For each variable found in this experiment, append the assay name to the
    # feature's entry in missing_in_exp (each entry is a vector)
    for (var in missing_in_exp){
      where_missing_vars[[var]] <-
        append(
          where_missing_vars[[var]],
          values = exp
        )
    }
  }

  # 6.2. Warn user if there are vars in multiple experiments. Do not pull data
  # in this case
  vars_multi_exp <-
    # Subset list from 6.1. for vars with more than one associated experiment
    Filter(
      f = function(x) {
        length(x) > 1
      },
      where_missing_vars
    ) |>
    names()

  
  if (length(vars_multi_exp) > 0){
    warning(
      "The following features were found in more than one alternate experiment. These features will not be included in the data returned: ",
      paste(vars_multi_exp, collapse = ', '),
      ". \n",
      "To include these features, please specify which experiment you would like to pull data from using the experiment name and an underscore (i.e. ",
      # Display an example with the experiment key added (using an exp that
      # the example is certain to be in)
      paste0(where_missing_vars[[vars_multi_exp[1]]][1], "_", vars_multi_exp[1]),
      ").",
      call. = FALSE,
      immediate. = TRUE
    )
  }
  
  # 6.3. Pull data for missing variables found in one alternate experiment
  # Update list of missing vars to exclude vars in one experiment
  missing_vars <-
    Filter(
      f = function(x){
        length(x) != 1
      },
      where_missing_vars
    ) |>
    names()

  # Subset missing vars for vars in one exp
  where_missing_vars <-
    Filter(
      f = function(x) {
        length(x) == 1
      },
      where_missing_vars
    )

  #
  for (var in names(where_missing_vars)){
    exp <- where_missing_vars[[var]]
    # Load alternate experiment
    alt_sce <- altExps(object)[[exp]]

    data <-
      assays(alt_sce)[[slot]][var, cells, drop = FALSE] |>
      # Only one var will be fetched at once in this case, so data can be added
      # as a vector to the list of fetched data
      as.vector()

    # Add experiment key to var
    keyed_var <- paste0(exp, "_", var)

    fetched_data[[keyed_var]] <- data

    # Edit vars to use the keyed var
    vars <-
      sub(
        pattern = paste0('^', var, '$'),
        replacement = keyed_var,
        x = vars
      )
  }
}

# 7. User warnings/errors
ten_plus_message <-
  if (length(x = missing_vars) > 10) {
    paste0(' (10 out of ', length(x = missing_vars), ' shown)')
  } else {
    ''
  }

if (length(x = missing_vars) == length(x = vars)) {
  stop(
    "None of the requested variables were found",
    ten_plus_message,
    ': ',
    paste(head(x = missing_vars, n = 10L), collapse = ', ')
  )
} else if (length(x = missing_vars) > 0) {
  warning(
    "The following requested variables were not found",
    ten_plus_message,
    ': ',
    paste(head(x = missing_vars, n = 10L), collapse = ', ')
  )
}

# 8. Construct data.frame and return to user
# Store names of vars fetched for downstream operations
fetched_vars <- names(fetched_data)

# Convert fetched_data to data.frame
fetched_data <-
  as.data.frame(
    fetched_data,
    row.names = cells,
    stringsAsFactors = FALSE
  )

print("fetched_data")
print(str(fetched_data))

# Re-order vars to reflect the order entered, instead of the order fetched
data_order <-
  na.omit(
    object =
      pmatch(
        x = vars,
        table = fetched_vars
      )
  )

if (length(x = data_order) > 1) {
  fetched_data <- fetched_data[, data_order]
}

# Change column names to reflect `vars` that were fetched
colnames(x = fetched_data) <- vars[vars %in% fetched_data]

print("fetched_data after ordering")
print(str(fetched_data))

#fetched_data


# ------------------------------------------------------------------------------
# For each feature, fetch data from object for the defined slot
# Set up features_found to record features for which data has been 
# successfully accessed
# features_found <- c()
# 
# data <-
#   lapply(
#     features,
#     function(feature, object, slot, features_found){
#       # 2.1. Determine the experiment "key" of the feature passed
#       # alphanumeric features to the left of an underscore will be treated as
#       # the key, and will be compared against the main and alternate experiment
#       # names.
# 
#       # Determine if the the entry is in "{experiment}_{feature}" format
#       if (grepl("^[[:alnum:]]+_.*", feature)){
#         # If so, extract experiment name from the assay
#         exp <-
#           gsub(
#             pattern = '(^[[:alnum:]]+)_.*',
#             replacement = "\\1",
#             x = feature,
#             fixed = FALSE
#             )
#         # Feature_name: the name of the feature with the experiment prefix
#         # removed. Used when searching the indicated experiment for the feature.
#         feature_name <-
#           gsub(
#             pattern = '^[[:alnum:]]+_(.*)',
#             replacement = "\\1",
#             x = feature,
#             fixed = FALSE
#             )
#       } else {
#         # If not, search for the feature within the main experiment
#         exp <- mainExpName(object)
#         feature_name <- feature
#       }
# 
#       # 2.2. Fetch data for feature from matrix
#       # Determine if feature is in the main experiment or an alternate experiment
#       if (exp == mainExpName(object)){
#         # Determine if the feature name is in the expression matrix under
#         # the defined slot
#         if (feature_name %in% rownames(assays(object)[[slot]])){
#           # Add feature to the list of features found (use the name of the 
#           # feature as entered, with the prefix if included)
#           features_found <- c(features_found, feature)
#           
#           # Pull feature row and transpose to column
#           assays(object)[[slot]][feature_name, , drop = TRUE] #|>
#             # as.data.frame() |>
#             # t()
#         } else {
#           # Display message to user if not found, and return nothing
#           warning(
#             glue::glue(
#               "Feature {feature_name} not found in the experiment {mainExpName(object)}."
#             )
#           )
# 
#           NULL
#         }
#       } else if (exp %in% altExpNames(object)){
#         # Load alternate experiment (also a SingleCellExperiment object)
#         alt_exp_data <- altExps(object)[[exp]]
# 
#         # Determine if the feature name is in the expression matrix under
#         # the defined slot
#         if (feature_name %in% rownames(assays(alt_exp_data)[[slot]])){
#           # Add feature to the list of features found (use the name of the 
#           # feature as entered, with the prefix if included)
#           features_found <- c(features_found, feature)
#           
#           assays(alt_exp_data)[[slot]][feature_name, , drop = TRUE] #|>
#             #as.data.frame() |>
#             #t()
#         } else {
#           # Display message to user if not found, and return nothing
#           warning(
#             glue::glue(
#               "Feature {feature_name} not found in the experiment {mainExpName(alt_exp_data)}."
#             )
#           )
# 
#           NULL
#         }
#       } else {
#         warning(glue::glue("No experiment found matching the entered key {exp}_ (for {feature})."))
# 
#         NULL
#       }
#     },
#     object,
#     slot,
#     features_found
#   )
# 
# # Apply feature names to list
# names(data) <- features
# 
# # Subset list for features for which information was accessed
# #data[features_found]
# 
# str(data)
# 
# #as.data.frame(data)
# #data
```

# Writing tests for FetchData method

Scripts below are based on Seurat FetchData results and will be used to test the SingleCellExperiment equivalent

```{r}
# Test A: keyed features are pulled from the correct assay
expected_table <- 
  FetchData(
    sobj,
    vars = 
      c("adt_CD117", 
        "rna_HOXA9", 
        # Nonexistent features
        "adt_CD900",
        # Metadata
        "nCount_RNA", 
        "nFeature_RNA", 
        # "Ambiguous" feature not in RNA assay
        "CD90"
        )
    )

# Expect 5 columns
ncol(expected_table) 

# Column sums of expected table
colSums(expected_table)
# Don't forget to use ignore_attr = TRUE when designing the expect statement 
```

# Testing FetchData.SingleCellExperiment

```{r}
FetchData(
    sce,
    slot = "logcounts",
    vars = 
      c("ADT_CD117", 
        "RNA_HOXA9", 
        # Nonexistent features
        "ADT_CD900",
        # Metadata
        "nCount_RNA", 
        "nFeature_RNA", 
        # "Ambiguous" feature not in RNA assay
        "CD90"
        )
    ) |> str()
```

# SCE method issue

## Tuesday, March 21st, 2023

If the script below is ran after starting a new R session, it is observed that the FetchData method works for singlecellexperiment classes regardless of whether SCEPlots is loaded.

```{r}
library(HDF5Array)

sce <- loadHDF5SummarizedExperiment(dir = "data/sce_hdf5/")

FetchData(
  sce,
  vars = "HOXA9"
  ) |> 
  str()

library(Seurat)

FetchData(
  sce,
  vars = "HOXA9"
  ) |> 
  str() 

DimPlot(
  sce,
  group.by = "clusters"
)

library(SCEPlots)

FetchData(
  sce,
  vars = "HOXA9"
  ) |> 
  str()

DimPlot(
  sce,
  group.by = "clusters"
)
```

# Testing speed of DimPlot function relative to Seurat implementation on the full AML object

The test below compares the time elapsed for 100 trials of a) SCEPlots::DimPlot ran on the full AML Seurat object, b) SCEPlots::DimPlot ran on the full AML SingleCellExperiment object, and c) Seurat::DimPlot ran on the full AML Seurat object.

```{r}
library(HDF5Array)

sobj <- readRDS("../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_annotated_sig_1k_v2.Rds")
sce <- loadHDF5SummarizedExperiment("../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce/")
```

Original SCEPlots::DimPlot function

```{r}
#------- Function copied and adapted from Seurat package -----------------------
# https://github.com/satijalab/seurat

#' Dimensional reduction plot
#'
#' Graphs the output of a dimensional reduction technique on a 2D scatter plot where each point is a
#' cell and it's positioned based on the cell embeddings determined by the reduction technique. The function accepts both Seurat and SingleCellExperiment objects.
#' For Seurat objects, cells are colored by their identity class by default, and for
#' SingleCellExperiment objects, cells are colored by the first metadata column in
#' colData(). The metadata variable used for coloring cells can be changed with the group_by parameter).
#'
#' The code for this function was from the {\link[Seurat Package]{https://github.com/satijalab/seurat/blob/master/R/visualization.R}} and adapted for use with
#' {\link[SingleCellExperiment]{https://www.bioconductor.org/packages/release/bioc/html/SingleCellExperiment.html}} objects.
#'
#' @param object  a Seurat object or a SingleCellExperiment object
#' @param dims Dimensions to plot, must be a two-length numeric vector specifying x- and y-dimensions i.e. c(1,2) to plot the first and second dimensions from the
#' reduction results.
#' @param cells Vector of cells to plot (default is all cells)
#' @param cols Vector of colors, each color corresponds to an identity class. This may also be a single character
#' or numeric value corresponding to a palette as specified by \code{\link[RColorBrewer]{brewer.pal.info}}.
#' By default, ggplot2 assigns colors. We also include a number of palettes from the pals package.
#' See \code{\link{DiscretePalette}} for details.
#' @param pt_size Adjust point size for plotting
#' @param reduction Which dimensionality reduction to use. If not specified, first searches for umap, then tsne, then pca
#' @param group_by Name of one or more metadata columns to group (color) cells by
#' (for example, orig.ident); pass 'ident' to group by identity class
#' @param split_by Name of a metadata column to split plot by;
#' see \code{\link{FetchData}} for more details
#' @param shape_by If NULL, all points are circles (default). You can specify any
#' cell attribute (that can be pulled with FetchData) allowing for both
#' different colors and different shapes on cells.  Only applicable if \code{raster = FALSE}.
#' @param order Specify the order of plotting for the idents. This can be
#' useful for crowded plots if points of interest are being buried. Provide
#' either a full list of valid idents or a subset to be plotted last (on top)
#' @param shuffle Whether to randomly shuffle the order of points. This can be
#' useful for crowded plots if points of interest are being buried. (default is FALSE)
#' @param seed Sets the seed if randomly shuffling the order of points.
#' @param label Whether to label the clusters
#' @param label_size Sets size of labels
#' @param label_color Sets the color of the label text
#' @param label_box Whether to put a box around the label text (geom_text vs
#' geom_label)
#' @param repel Repel labels
#' @param cells_highlight A list of character or numeric vectors of cells to
#' highlight. If only one group of cells desired, can simply
#' pass a vector instead of a list. If set, colors selected cells to the color(s)
#' in \code{cols_highlight} and other cells black (white if dark.theme = TRUE);
#' will also resize to the size(s) passed to \code{sizes_highlight}
#' @param cols_highlight A vector of colors to highlight the cells as; will
#' repeat to the length groups in cells_highlight
#' @param sizes_highlight Size of highlighted cells; will repeat to the length
#' groups in cells_highlight
#' @param na_value Color value for NA points when using custom scale
#' @param ncol Number of columns for display when combining plots
#' @param combine Combine plots into a single \code{\link[patchwork]{patchwork}ed}
#' ggplot object. If \code{FALSE}, return a list of ggplot objects
#' @param raster Convert points to raster format, default is \code{NULL} which
#' automatically rasterizes if plotting more than 100,000 cells
#' @param raster_dpi Pixel resolution for rasterized plots, passed to geom_scattermore().
#' Default is c(512, 512).
#'
#' @return A \code{\link[patchwork]{patchwork}ed} ggplot object if
#' \code{combine = TRUE}; otherwise, a list of ggplot objects
#'
DimPlot_orig <- function(
    object,
    dims = c(1, 2),
    cells = NULL,
    cols = NULL,
    pt_size = NULL,
    reduction = NULL,
    group_by = NULL,
    split_by = NULL,
    shape_by = NULL,
    order = NULL,
    shuffle = FALSE,
    seed = 1,
    label = FALSE,
    label_size = 4,
    label_color = 'black',
    label_box = FALSE,
    repel = FALSE,
    cells_highlight = NULL,
    cols_highlight = '#DE2D26',
    sizes_highlight = 1,
    na_value = 'grey50',
    ncol = NULL,
    combine = TRUE,
    raster = NULL,
    raster_dpi = c(512, 512)
) {
  if (length(x = dims) != 2) {
    stop("'dims' must be a two-length vector")
  }

  # Compile data for plotting: methods depend on object type
  if (is(object, "SingleCellExperiment")){
    # For SingleCellExperiment objects
    # 1. Define reduction (defaults to the first reduction stored for sce objects)
    # Uses rlang %||% infix
    reduction <- reduction %||% SingleCellExperiment::reducedDimNames(object)[1]
    # 2. Define cells to include in plot
    ## Same as for seurat object ##
    cells <- cells %||% BiocGenerics::colnames(object)

    # 3. Fetch dimensional reduction data from object
    data <- SingleCellExperiment::reducedDims(object)[[reduction]][cells, dims]
    data <- BiocGenerics::as.data.frame(data)

    # 4. Fetch names of dimensions to plot
    # For SCE objects, use the column names for the requested dim indices
    # (there is no `Key()` method for SingleCellExperiment objects)
    dim_names <- colnames(data)[dims]

    # 5. Process group by selection
    # There is no "ident" property for SingleCellExperiment objects, so defaults
    # will be chosen based on the first metadata column, rather than the current ident class
    # Store original entry for group_by
    orig_groups <- group_by

    if (is.null(group_by)){
      stop("group_by must not be NULL for SingleCellExperiment objects.")
    }

    # 6. Bind group by metadata to the table of reduction coordinates
    data <-
      cbind(
        data,
        # Subsets for selected cells, and the names of entered group_by columns
        colData(object)[cells, group_by, drop = FALSE]
      )

    # 7. Define group_by variables to iterate through
    group_by_cols <-
      colnames(data)[3:ncol(data)]

    # 8. Convert group by columns to factors if they are not already
    for (group in group_by_cols) {
      if (!is.factor(data[, group])) {
        data[, group] <- factor(data[, group])
      }
    }

    # 9. Add shape_by data if it exists
    if (!is.null(x = shape_by)) {
      data[, shape_by] <- colData(object)[cells, shape_by, drop = TRUE]
    }

    # 10. Same for split_by data
    if (!is.null(x = split_by)) {
      data[, split_by] <- colData(object)[cells, split_by, drop = TRUE]
    }

    # 11. If sufffle is TRUE, randomly shuffle cells
    if (isTRUE(shuffle)) {
      set.seed(seed = seed)
      data <- data[sample(x = 1:nrow(x = data)), ]
    }
  } else if (is(object, "Seurat")){
    # For Seurat Objects
    # Determine reduction to use (if NULL, use default))
    # %||% infix is from rlang
    reduction <- reduction %||% DefaultDimReduc(object = object)
    # Read parameter for cells to plot (defaults to all cells)
    cells <- cells %||% colnames(x = object)

    # Fetch data for chosen reduction from object
    # subset for chosen cells and dims
    data <- Embeddings(object = object[[reduction]])[cells, dims]
    # Convert to data.frame (default is a matrix)
    data <- as.data.frame(x = data)
    # Form names for dim reduction coordinates on the x- and y- axis
    dim_names <-
      paste0(
        # Use the key of the *reduction* chosen by the
        # user (or the default reduction)
        Key(object = object[[reduction]]),
        dims
      )

    # Set group by to the current ident class if it is NULL
    # Store current ident class
    object[['ident']] <- Idents(object = object)
    # Store group by variable in `orig_groups`
    orig_groups <- group_by
    group_by <- group_by %||% 'ident'

    # Add values of the group_by metadata variable(s) for
    # each cell to the reduction data
    data <-
      cbind(
        data,
        object[[group_by]][cells, , drop = FALSE]
      )

    # Explicitly define group_by as the column names for each metadata variable
    # added to the reduction matrix above
    group_by_cols <- colnames(x = data)[3:ncol(x = data)]

    # If any of the metadata columns are not factors, coerce them into factors.
    for (group in group_by) {
      if (!is.factor(x = data[, group])) {
        data[, group] <- factor(x = data[, group])
      }
    }

    # Add data for shape_by metadata variable if it exists
    if (!is.null(x = shape_by)) {
      data[, shape_by] <- object[[shape_by, drop = TRUE]]
    }

    # Same for split_by metadata variable
    if (!is.null(x = split_by)) {
      data[, split_by] <- object[[split_by, drop = TRUE]]
    }

    # Randomly shuffle cells if specified by the user
    if (isTRUE(x = shuffle)) {
      set.seed(seed = seed)
      data <- data[sample(x = 1:nrow(x = data)), ]
    }
  } else {
    # Throw an error for unsupported data types
    stop("Object entered is not a SinglecellExperiment or a Seurat object.")
  }

  # For each group by variable, create a DimPlot of cells grouped by that variable.
  plots <- lapply(
    X = group_by_cols,
    FUN = function(group) {
      plot <- Seurat::SingleDimPlot(
        data = data[, c(dim_names, group, split_by, shape_by)],
        dims = dim_names,
        col.by = group,
        # cols: a categorical pallete in this case
        cols = cols,
        pt.size = pt_size,
        shape.by = shape_by,
        order = order,
        label = FALSE,
        # Cells to highlight
        cells.highlight = cells_highlight,
        cols.highlight = cols_highlight,
        sizes.highlight = sizes_highlight,
        na.value = na_value,
        raster = raster,
        raster.dpi = raster_dpi
      )
      if (label) {
        plot <-
          Seurat::LabelClusters(
            plot = plot,
            id = group,
            repel = repel,
            size = label_size,
            split.by = split_by,
            box = label_box,
            color = label_color
          )
      }
      if (!is.null(x = split_by)) {
        plot <-
          plot +
          Seurat:::FacetTheme() +
          ggplot2::facet_wrap(
            # rlang injection operator
            # ?`!!` for more information
            facets = vars(!!sym(x = split_by)),
            ncol = if (length(x = group_by) > 1 || is.null(x = ncol)) {
              length(x = unique(x = data[, split_by]))
            } else {
              ncol
            }
          )
      }
      plot <- if (is.null(x = orig_groups)) {
        plot + labs(title = NULL)
      } else {
        plot + CenterTitle()
      }
    }
  )
  if (!is.null(x = split_by)) {
    ncol <- 1
  }
  if (combine) {
    plots <-
      patchwork::wrap_plots(
        plots,
        # %iff% infix (Seurat package)
        # Uses ncol if orig_groups is not NULL, otherwise uses NULL
        ncol = orig_groups %iff% ncol
      )
  }
  return(plots)
}
```

SCEPlots::DimPlot with FetchData

```{r}
#------- Function copied and adapted from Seurat package -----------------------
# https://github.com/satijalab/seurat

#' Dimensional reduction plot
#'
#' Graphs the output of a dimensional reduction technique on a 2D scatter plot where each point is a
#' cell and it's positioned based on the cell embeddings determined by the reduction technique. The function accepts both Seurat and SingleCellExperiment objects.
#' For Seurat objects, cells are colored by their identity class by default, and for
#' SingleCellExperiment objects, cells are colored by the first metadata column in
#' colData(). The metadata variable used for coloring cells can be changed with the group_by parameter).
#'
#' The code for this function was from the {\link[Seurat Package]{https://github.com/satijalab/seurat/blob/master/R/visualization.R}} and adapted for use with
#' {\link[SingleCellExperiment]{https://www.bioconductor.org/packages/release/bioc/html/SingleCellExperiment.html}} objects.
#'
#' @param object  a Seurat object or a SingleCellExperiment object
#' @param dims Dimensions to plot, must be a two-length numeric vector specifying x- and y-dimensions i.e. c(1,2) to plot the first and second dimensions from the
#' reduction results.
#' @param cells Vector of cells to plot (default is all cells)
#' @param cols Vector of colors, each color corresponds to an identity class. This may also be a single character
#' or numeric value corresponding to a palette as specified by \code{\link[RColorBrewer]{brewer.pal.info}}.
#' By default, ggplot2 assigns colors. We also include a number of palettes from the pals package.
#' See \code{\link{DiscretePalette}} for details.
#' @param pt_size Adjust point size for plotting
#' @param reduction Which dimensionality reduction to use. If not specified, first searches for umap, then tsne, then pca
#' @param group_by Name of one or more metadata columns to group (color) cells by
#' (for example, orig.ident); pass 'ident' to group by identity class
#' @param split_by Name of a metadata column to split plot by;
#' see \code{\link{FetchData}} for more details
#' @param shape_by If NULL, all points are circles (default). You can specify any
#' cell attribute (that can be pulled with FetchData) allowing for both
#' different colors and different shapes on cells.  Only applicable if \code{raster = FALSE}.
#' @param order Specify the order of plotting for the idents. This can be
#' useful for crowded plots if points of interest are being buried. Provide
#' either a full list of valid idents or a subset to be plotted last (on top)
#' @param shuffle Whether to randomly shuffle the order of points. This can be
#' useful for crowded plots if points of interest are being buried. (default is FALSE)
#' @param seed Sets the seed if randomly shuffling the order of points.
#' @param label Whether to label the clusters
#' @param label_size Sets size of labels
#' @param label_color Sets the color of the label text
#' @param label_box Whether to put a box around the label text (geom_text vs
#' geom_label)
#' @param repel Repel labels
#' @param cells_highlight A list of character or numeric vectors of cells to
#' highlight. If only one group of cells desired, can simply
#' pass a vector instead of a list. If set, colors selected cells to the color(s)
#' in \code{cols_highlight} and other cells black (white if dark.theme = TRUE);
#' will also resize to the size(s) passed to \code{sizes_highlight}
#' @param cols_highlight A vector of colors to highlight the cells as; will
#' repeat to the length groups in cells_highlight
#' @param sizes_highlight Size of highlighted cells; will repeat to the length
#' groups in cells_highlight
#' @param na_value Color value for NA points when using custom scale
#' @param ncol Number of columns for display when combining plots
#' @param combine Combine plots into a single \code{\link[patchwork]{patchwork}ed}
#' ggplot object. If \code{FALSE}, return a list of ggplot objects
#' @param raster Convert points to raster format, default is \code{NULL} which
#' automatically rasterizes if plotting more than 100,000 cells
#' @param raster_dpi Pixel resolution for rasterized plots, passed to geom_scattermore().
#' Default is c(512, 512).
#'
#' @return A \code{\link[patchwork]{patchwork}ed} ggplot object if
#' \code{combine = TRUE}; otherwise, a list of ggplot objects
#'
#' @import rlang
#' @import Seurat
#' @importFrom ggplot2 facet_wrap vars sym labs
#' @importFrom SeuratObject DefaultDimReduc
#' @importFrom patchwork wrap_plots
#' @importFrom SingleCellExperiment reducedDimNames reducedDims colData
#'
#' @export
#'
DimPlot_FetchData <- function(
    object,
    dims = c(1, 2),
    cells = NULL,
    cols = NULL,
    pt_size = NULL,
    reduction = NULL,
    group_by = NULL,
    split_by = NULL,
    shape_by = NULL,
    order = NULL,
    shuffle = FALSE,
    seed = 1,
    label = FALSE,
    label_size = 4,
    label_color = 'black',
    label_box = FALSE,
    repel = FALSE,
    cells_highlight = NULL,
    cols_highlight = '#DE2D26',
    sizes_highlight = 1,
    na_value = 'grey50',
    ncol = NULL,
    combine = TRUE,
    raster = NULL,
    raster_dpi = c(512, 512)
) {
  if (length(x = dims) != 2) {
    stop("'dims' must be a two-length vector")
  }

  # Require group_by to be defined for SingleCellExperiment objects
  if (is(object, "SingleCellExperiment")){
    if (is.null(group_by)){
      stop("For SingleCellExperiment objects, `group_by` must be defined.")
    }
  }

  # 1. Define reduction (defaults to the first reduction stored for sce objects)
  # Uses rlang %||% infix
  reduction <- reduction %||% default_reduction(object)
  # 2. Define cells to include in plot
  ## Same as for Seurat object ##
  cells <- cells %||% get_all_cells(object)

  # Fetch dimensional reduction data from object
  # 3. Convert dims to format readable by FetchData (<reduction>_<dim>)
  dim_names <- reduction_dimnames(object, reduction = reduction, dims = dims)

  # 4. Identify group_by variable, store in orig_groups
  # orig_groups is used to test whether the group_by was set by the user
  orig_groups <- group_by
  # Ident does not exist for SingleCellExperiment objects, but this will never
  # be applied since group_by will always be defined.
  group_by <- group_by %||% 'ident'

  # 5. Fetch reduction coordinates and group by metadata
  data <-
    FetchData(
      object = object,
      vars = c(dim_names, group_by),
      cells = cells
      )

  # Throw an error if reduction coordinates or group_by data were not
  # properly returned
  if (!all(dim_names %in% colnames(data))) {
    stop("The dimensions requested were not found.", call. = FALSE)
  } else if (!all(group_by %in% colnames(data))){
    stop("The group_by variable(s) requested were not found.", call. = FALSE)
  }

  print("colnames of data")
  print(colnames(data))

  # 6. Define group_by variables to iterate through
  group_by_cols <-
    colnames(data)[3:ncol(data)]

  print("group_by_cols")
  print(group_by_cols)

  # 7. Convert group by columns to factors if they are not already
  print("7. Group by columns to factor")
  for (group in group_by_cols) {
    print(group)
    if (!is.factor(data[, group])) {
      data[, group] <- factor(data[, group])
    }
  }

  print("8. shape_by data")
  # 8. Add shape_by data if it exists
  if (!is.null(x = shape_by)) {
    data[, shape_by] <-
      FetchData(
        object = object,
        vars = shape_by,
        cells = cells
        )
  }

  # 9. Same for split_by data
  if (!is.null(x = split_by)) {
    data[, split_by] <-
      FetchData(
        object = object,
        vars = split_by,
        cells = cells
        )
  }

  # 10. If shufffle is TRUE, randomly shuffle cells
  if (isTRUE(shuffle)) {
    set.seed(seed = seed)
    data <- data[sample(x = 1:nrow(x = data)), ]
  }

  # # Compile data for plotting: methods depend on object type
  # if (is(object, "SingleCellExperiment")){
  #   # For SingleCellExperiment objects
  #   # 1. Define reduction (defaults to the first reduction stored for sce objects)
  #   # Uses rlang %||% infix
  #   reduction <- reduction %||% SingleCellExperiment::reducedDimNames(object)[1]
  #   # 2. Define cells to include in plot
  #   ## Same as for seurat object ##
  #   cells <- cells %||% BiocGenerics::colnames(object)
  #
  #   # 3. Fetch dimensional reduction data from object
  #   data <- SingleCellExperiment::reducedDims(object)[[reduction]][cells, dims]
  #   data <- BiocGenerics::as.data.frame(data)
  #
  #   # 4. Fetch names of dimensions to plot
  #   # For SCE objects, use the column names for the requested dim indices
  #   # (there is no `Key()` method for SingleCellExperiment objects)
  #   dim_names <- colnames(data)[dims]
  #
  #   # 5. Process group by selection
  #   # There is no "ident" property for SingleCellExperiment objects
  #   # Store original entry for group_by
  #   orig_groups <- group_by
  #
  #   if (is.null(group_by)){
  #     stop("group_by must not be NULL for SingleCellExperiment objects.")
  #   }
  #
  #   # 6. Bind group by metadata to the table of reduction coordinates
  #   data <-
  #     cbind(
  #       data,
  #       # Subsets for selected cells, and the names of entered group_by columns
  #       colData(object)[cells, group_by, drop = FALSE]
  #     )
  #
  #
  #
  #
  # } else if (is(object, "Seurat")){
  #   # For Seurat Objects
  #   # Determine reduction to use (if NULL, use default))
  #   # %||% infix is from rlang
  #   reduction <- reduction %||% DefaultDimReduc(object = object)
  #   # Read parameter for cells to plot (defaults to all cells)
  #   cells <- cells %||% colnames(x = object)
  #
  #   # Fetch data for chosen reduction from object
  #   # subset for chosen cells and dims
  #   data <- Embeddings(object = object[[reduction]])[cells, dims]
  #   # Convert to data.frame (default is a matrix)
  #   data <- as.data.frame(x = data)
  #   # Form names for dim reduction coordinates on the x- and y- axis
  #   dim_names <-
  #     paste0(
  #       # Use the key of the *reduction* chosen by the
  #       # user (or the default reduction)
  #       Key(object = object[[reduction]]),
  #       dims
  #     )
  #
  #   # Set group by to the current ident class if it is NULL
  #   # Store current ident class
  #   object[['ident']] <- Idents(object = object)
  #   # Store group by variable in `orig_groups`
  #   orig_groups <- group_by
  #   group_by <- group_by %||% 'ident'
  #
  #   # Add values of the group_by metadata variable(s) for
  #   # each cell to the reduction data
  #   data <-
  #     cbind(
  #       data,
  #       object[[group_by]][cells, , drop = FALSE]
  #     )
  #
  #   # Explicitly define group_by as the column names for each metadata variable
  #   # added to the reduction matrix above
  #   group_by_cols <- colnames(x = data)[3:ncol(x = data)]
  #
  #   # If any of the metadata columns are not factors, coerce them into factors.
  #   for (group in group_by) {
  #     if (!is.factor(x = data[, group])) {
  #       data[, group] <- factor(x = data[, group])
  #     }
  #   }
  #
  #   # Add data for shape_by metadata variable if it exists
  #   if (!is.null(x = shape_by)) {
  #     data[, shape_by] <- object[[shape_by, drop = TRUE]]
  #   }
  #
  #   # Same for split_by metadata variable
  #   if (!is.null(x = split_by)) {
  #     data[, split_by] <- object[[split_by, drop = TRUE]]
  #   }
  #
  #   # Randomly shuffle cells if specified by the user
  #   if (isTRUE(x = shuffle)) {
  #     set.seed(seed = seed)
  #     data <- data[sample(x = 1:nrow(x = data)), ]
  #   }
  # } else {
  #   # Throw an error for unsupported data types
  #   stop("Object entered is not a SinglecellExperiment or a Seurat object.")
  # }

  # For each group by variable, create a DimPlot of cells grouped by that variable.
  plots <- lapply(
    X = group_by_cols,
    FUN = function(group) {
      plot <- Seurat::SingleDimPlot(
        data = data[, c(dim_names, group, split_by, shape_by)],
        dims = dim_names,
        col.by = group,
        # cols: a categorical pallete in this case
        cols = cols,
        pt.size = pt_size,
        shape.by = shape_by,
        order = order,
        label = FALSE,
        # Cells to highlight
        cells.highlight = cells_highlight,
        cols.highlight = cols_highlight,
        sizes.highlight = sizes_highlight,
        na.value = na_value,
        raster = raster,
        raster.dpi = raster_dpi
      )
      if (label) {
        plot <-
          Seurat::LabelClusters(
            plot = plot,
            id = group,
            repel = repel,
            size = label_size,
            split.by = split_by,
            box = label_box,
            color = label_color
          )
      }
      if (!is.null(x = split_by)) {
        plot <-
          plot +
          Seurat:::FacetTheme() +
          ggplot2::facet_wrap(
            # rlang injection operator
            # ?`!!` for more information
            facets = vars(!!sym(x = split_by)),
            ncol = if (length(x = group_by) > 1 || is.null(x = ncol)) {
              length(x = unique(x = data[, split_by]))
            } else {
              ncol
            }
          )
      }
      plot <- if (is.null(x = orig_groups)) {
        plot + labs(title = NULL)
      } else {
        plot + CenterTitle()
      }
    }
  )
  if (!is.null(x = split_by)) {
    ncol <- 1
  }
  if (combine) {
    plots <-
      patchwork::wrap_plots(
        plots,
        # %iff% infix (Seurat package)
        # Uses ncol if orig_groups is not NULL, otherwise uses NULL
        ncol = orig_groups %iff% ncol
        )
  }
  return(plots)
}

```

```{r}
#' Function to run trials on each function
#'
#' @param funcs a named vector of functions to run. Time trial results are 
#' returned for each function, labeled according to the names passed.
#' @param params A vector of lists of parameters passed to each function. The length of
#' the list must match the length of funs
#' @param n the number of trials to run for each function
multi_time_trial <- function(funcs, params, n){
  test <- c()
  time <- c()
  
  if (!length(funcs) == length(params)){
    stop("funcs and params must be of equal length.")
  }
  
  for (i in 1:length(funcs)){
    func_results <- 
      repeat_trial(
      func = funcs[i], 
      n = n,
      params[i]
      )
    
    time <- c(time, func_results)
    test <- c(test, rep_len(names(funcs)[i], 100))
  }
  
  # Construct data.frame from results and return
  data.frame(
    list(
    "Test" = test, 
    "Time" = time
    )
  )
}

# time_data <- 
#   multi_time_trial(
#     funcs = 
#       c("SCEPlots_seurat" = SCEPlots::DimPlot,
#         "SCEPlots_SCE" = SCEPlots::DimPlot)
#   )

test <- c()
time <- c()

# 1.
# Full AML Seurat object, latest SCEPlots function
results <- 
  repeat_trial(
    func = SCEPlots::DimPlot, 
    n = 100,
    object = sobj,
    group_by = "velten_clusters"
    )

time <- c(time, results)
test <- c(test, rep_len("SCEPlots_v3_seurat", 100))

# 2.
# Full AML SCE object, latest SCEPlots function
results <- 
  repeat_trial(
    func = SCEPlots::DimPlot, 
    n = 100,
    object = sce,
    group_by = "velten_clusters"
    )

time <- c(time, results)
test <- c(test, rep_len("SCEPlots_v3_SCE", 100))

# 3.
# Full AML Seurat object, SCEPlots v1
results <- 
  repeat_trial(
    func = DimPlot_FetchData, 
    n = 100,
    object = sobj,
    group_by = "velten_clusters"
    )

time <- c(time, results)
test <- c(test, rep_len("SCEPlots_v2_seurat", 100))

# 4. 
# Full AML SCE object, SCEPlots v1
results <- 
  repeat_trial(
    func = DimPlot_FetchData, 
    n = 100,
    object = sce,
    group_by = "velten_clusters"
    )

time <- c(time, results)
test <- c(test, rep_len("SCEPlots_v2_SCE", 100))

# 5.
# Full AML Seurat object, SCEPlots v1
results <- 
  repeat_trial(
    func = DimPlot_orig, 
    n = 100,
    object = sobj,
    group_by = "velten_clusters"
    )

time <- c(time, results)
test <- c(test, rep_len("SCEPlots_v1_seurat", 100))

# 6.
# Full AML SCE object, SCEPlots v1
results <- 
  repeat_trial(
    func = DimPlot_orig, 
    n = 100,
    object = sce,
    group_by = "velten_clusters"
    )

time <- c(time, results)
test <- c(test, rep_len("SCEPlots_v1_SCE", 100))

# 7.
# Full AML Seurat object, Seurat
results <- 
  repeat_trial(
    func = Seurat::DimPlot, 
    n = 100,
    object = sobj,
    group.by = "velten_clusters"
    )

time <- c(time, results)
test <- c(test, rep_len("seurat_seurat", 100))

# for (i in 1:100){
#   cat(paste0("Trial ", i))
#   
#   suppressMessages({
#   # SCEPlots with a Seurat object
#   tic()
#   SCEPlots::DimPlot(sobj, group_by = "velten_clusters")
#   elapsed <- toc()
#   
#   test <-
#     c(test, "SCEPlots_seurat")
#   time <- 
#     c(time, as.numeric(elapsed$toc - elapsed$tic))
#   })
#   
#   cat("\r")
# }
# 
# for (i in 1:100){
#   cat(paste0("Trial ", i))
#   
#   suppressMessages({
#   
#   # SCEPlots with an SCE object
#   tic()
#   SCEPlots::DimPlot(sce, group_by = "velten_clusters")
#   elapsed <- toc()
#   
#   test <-
#     c(test, "SCEPlots_SCE")
#   time <- 
#     c(time, as.numeric(elapsed$toc - elapsed$tic))
#   })
#   
#   cat("\r")
# }
# 
# for (i in 1:100){
#   cat(paste0("Trial ", i))
#   
#   suppressMessages({
#   # Seurat with a Seurat object
#   tic()
#   Seurat::DimPlot(sobj, group.by = "velten_clusters")
#   elapsed <- toc()
#   
#   test <-
#     c(test, "Seurat_seurat")
#   time <- 
#     c(time, as.numeric(elapsed$toc - elapsed$tic))
#   })
#   
#   cat("\r")
# }

# Construct a data frame from the results
time_data <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time
    )
  )

# Print a summary table with the average time taken for each function
time_data |> 
  group_by(Test) |> 
  summarize(
    average_time = mean(Time)
  )

ggplot(data = time_data, aes(x = Test, y = Time)) +
  geom_boxplot(aes(fill = Test)) #+
  #scale_color_discrete(c("#880000", "#898800", "#000088"))
```

```{r}
latest_comparison <- 
  time_data |> filter(Test %in% c("SCEPlots_v3_SCE", "SCEPlots_v3_seurat", "seurat_seurat"))

rename_vector <- 
  c("SCEPlots_v3_SCE" = "SCEPlots, SCE Object",
    "SCEPlots_v3_seurat" = "SCEPlots, Seurat Object",
    "seurat_seurat" = "Seurat v5, Seurat Object"
    )

ggplot(data = latest_comparison, aes(x = Test, y = Time)) +
  geom_boxplot(aes(color = Test)) +
   scale_x_discrete(
     labels = rename_vector
          ) +
  scale_y_continuous(
    breaks = seq(from = 0, to = 0.7, by = 0.1),
    limits = c(0, 0.7)
    ) +
  scale_color_manual(
    values = 
      c("#880000", "#0000AA", "#000000"),
    aesthetics = "color",
    labels = rename_vector,
    na.value = "grey50"
    ) +
  theme_cowplot() +
  ggtitle("Comparison of DimPlot Speed") +
  xlab("Function") +
  ylab("Runtime") +
  # Legend title
  guides(color = guide_legend(title = "Function")) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 20),
    legend.title = element_text(face = "bold"), 
    axis.title.x = element_text(face = "bold"),
    axis.title.y = element_text(face = "bold")
    )
```

# Trial of FetchData for reductions

Part 1: Seurat Object vs. SingleCellExperiment objects

```{r}
time <- c()
test <- c()

dimnames <- c("UMAP_1", "UMAP_2")

# Seurat objects
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sobj,
    vars = dimnames
    )

time <- c(time, results)
test <- c(test, rep_len("FetchData_Seurat", 100))

# SCE objects
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce,
    vars = dimnames
    )

time <- c(time, results)
test <- c(test, rep_len("FetchData_SCE", 100))

fetchdata_results <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time
    )
  )

ggplot(data = fetchdata_results, aes(x = Test, y = Time)) +
  geom_boxplot(aes(fill = Test)) #+
  scale_color_manual(
    values = 
      c("#880000", "#000088"),
    aesthetics = "fill",
    na.value = "grey50"
    )
```

Part 2: Compare FetchData to direct accession of reduction coordinates for both objects

```{r}
# Function to fetch reduction coordinates for SingleCellExperiment obejcts
direct_accession_sce <- 
  function(object, reduction, dims = c(1,2)){
    cells <- colnames(object)
    
    data <- reducedDims(object)[[reduction]][cells, dims]
    as.data.frame(data)
  }

# Equivalent for Seurat objects (taken from Seurat::DimPlot)
direct_accession_seurat <- 
  function(object, reduction, dims = c(1,2)){
    # Include all cells
    cells <- colnames(object)
    
    data <- Embeddings(object = object[[reduction]])[cells, dims]
    as.data.frame(x = data)
  }

# Trials of each function, compared to fetchdata
time <- c()
test <- c()

dimnames <- c("UMAP_1", "UMAP_2")

reduction_sobj <- "umap"
reduction_sce <- "UMAP"

# FetchData, Seurat objects
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sobj,
    vars = dimnames
    )

time <- c(time, results)
test <- c(test, rep_len("FetchData_Seurat", 100))

# FetchData, SCE objects
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce,
    vars = dimnames
    )

time <- c(time, results)
test <- c(test, rep_len("FetchData_SCE", 100))

# Direct accession, Seurat objects
results <- 
  repeat_trial(
    func = direct_accession_seurat, 
    n = 100,
    object = sobj,
    reduction = reduction_sobj
    )

time <- c(time, results)
test <- c(test, rep_len("Direct_accession_Seurat", 100))

# Direct accession, SCE objects
results <- 
  repeat_trial(
    func = direct_accession_sce, 
    n = 100,
    object = sce,
    reduction = reduction_sce
    )

time <- c(time, results)
test <- c(test, rep_len("Direct_accession_SCE", 100))

direct_acc_v_fetchdata <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time
    )
  )

direct_acc_v_fetchdata$Test <- 
  factor(
    direct_acc_v_fetchdata$Test, 
    levels = 
      c("FetchData_SCE", 
        "Direct_accession_SCE", 
        "FetchData_Seurat",
        "Direct_accession_Seurat" 
        )
    )

ggplot(data = direct_acc_v_fetchdata, aes(x = Test, y = Time)) +
  geom_boxplot(aes(color = Test)) +
  scale_color_manual(
    values = 
      c("#880000", "#000088", "#008800", "#B8AB2F"),
    aesthetics = "color",
    na.value = "grey50"
    )
```

## Is the fetch_metadata method faster than FetchData?

The performance of the S3 method created to fetch metadata will be compared to the performance of the FetchData method.

### Comparison for a single metadata feature

```{r}
# Trials of each function, compared to fetchdata
time <- c()
test <- c()

meta_colname <- "leiden_clusters"

cells_sobj <- get_all_cells(sobj)
cells_sce <- get_all_cells(sce_3)

# FetchData, Seurat objects
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sobj,
    vars = meta_colname
    )

time <- c(time, results)
test <- c(test, rep_len("FetchData_Seurat", 100))

# FetchData, SCE objects
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_3,
    vars = meta_colname
    )

time <- c(time, results)
test <- c(test, rep_len("FetchData_SCE", 100))

# fetch_metadata method, Seurat objects
results <- 
  repeat_trial(
    func = fetch_metadata, 
    n = 100,
    object = sobj,
    vars = meta_colname,
    cells = cells_sobj
    )

time <- c(time, results)
test <- c(test, rep_len("fetch_metadata_Seurat", 100))

# Direct accession, SCE objects
results <- 
  repeat_trial(
    func = fetch_metadata, 
    n = 100,
    object = sce_3,
    vars = meta_colname,
    cells = cells_sce
    )

time <- c(time, results)
test <- c(test, rep_len("fetch_metadata_SCE", 100))

results_df <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time
    )
  )

results_df$Test <- 
  factor(
    results_df$Test, 
    levels = 
      c("FetchData_SCE", 
        "fetch_metadata_SCE", 
        "FetchData_Seurat",
        "fetch_metadata_Seurat" 
        )
    )

ggplot(data = results_df, aes(x = Test, y = Time)) +
  geom_boxplot(aes(color = Test)) +
  scale_color_manual(
    values = 
      c("#880000", "#000088", "#008800", "#B8AB2F"),
    aesthetics = "color",
    na.value = "grey50"
    )

# ggsave(
#   "./FetchData_vs_fetch_metadata.png", 
#   device = "png",
#   bg = "#FFFFFF"
#   )
```

The fetch_metadata method is considerably faster than FetchData.

### How does fetch_metadata scale with the number of features?

```{r}
# Trials of each function, compared to fetchdata
time <- c()
test <- c()
n_features <- c()

meta_colname <- "leiden_clusters"

#cells_sobj <- get_all_cells(sobj)
cells_sce <- get_all_cells(sce_3)

# Greatest amount of n_features to include while testing
max_n_features <- 20
# FetchData, SCE objects
for (i in 1:max_n_features){
  cat("FetchData on SCE object, n_features =", i, "\n")
  # Select metadata columns
  meta_cols <- names(colData(sce_3))[1:i]
  trials <- 25
  trial_name <- "FetchData_SCE"
  
  # Trial for n_features == i
  results <- 
    repeat_trial(
      func = FetchData, 
      n = trials,
      object = sce_3,
      vars = meta_cols
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  # Record number of features for the trial (as character)
  n_features <- 
    c(n_features, 
      rep_len(
        as.character(i), 
        trials
        )
      )
}

# fetch_metadata, SCE object
for (i in 1:max_n_features){
  cat("fetch_metadata on SCE object, n_features =", i, "\n")
  # Select metadata columns
  meta_cols <- names(colData(sce_3))[1:i]
  trials <- 25
  trial_name <- "fetch_metadata_SCE"
  
  # Trial for n_features == i
  results <- 
    repeat_trial(
      func = fetch_metadata, 
      n = trials,
      object = sce_3,
      vars = meta_cols,
      cells = cells_sce
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  # Record number of features for the trial (as character)
  n_features <- 
    c(n_features, 
      rep_len(
        as.character(i), 
        trials
        )
      )
}

results_df <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time,
    "Features" = n_features
    )
  )

results_df$Features <-
  factor(
    results_df$Features, 
    levels = 
      str_sort(
        results_df$Features |> unique(), 
        numeric = TRUE
        )
    )

plot <- 
  ggplot(data = results_df, aes(x = Features, y = Time)) +
  geom_boxplot(aes(color = Test)) +
  scale_color_manual(
      values = ggsci::pal_aaas("default")(10)[c(1,3)],
      aesthetics = "color",
      na.value = "grey50"
      ) +
  scale_y_log10(
    limits = c(0.005, 1)
  ) +
  # scale_y_continuous(
  #   breaks = seq(from = 0, to = 0.5, by = 0.05),
  #   limits = c(0, 0.5)#,
  #   #labels = function(breaks){paste0(breaks, " s")}
  #   ) +
  ylab("Time (s)") +
  xlab("Number of Features") +
  labs(
    title = "Metadata Retrieval Time",
    subtitle = 
      "(SingleCellExperiment Object, 200k Cells x 29k Genes, HDF5Array Compression Level 3)"
  ) +
  guides(
    color = 
      guide_legend(
        title = NULL
        )
  ) +
  theme_cowplot() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 18),
    plot.subtitle = element_text(hjust = 0.5),
    axis.text.x = element_text(size = 9)
    )

plot
```


# Tuesday April 18th, 2023

## Does FetchData perform more slowly than direct accession for features?

The tests below are for a single feature from the RNA assay (BCL2).

```{r}
# Function to fetch reduction coordinates for SingleCellExperiment obejcts
direct_feature_access_sce <- 
  function(object, assay, feature){
    # Inlcude all cells in demo, and use logcounts slot
    cells <- colnames(object)
    slot <- "logcounts"

    exp_use <- 
      if (assay %in% altExpNames(object)){
        altExps(object)[[assay]]
      } else {
        sce
      }
    
    # data <-
    #   assays(exp_use)[[slot]][feature, cells, drop = FALSE] |>
    #   as.matrix() |>
    #   t()
    data <- assays(exp_use)[[slot]][feature, cells, drop = FALSE] |> t()
    
    data <- as.data.frame(data)
    
    colnames(data) <- paste0(assay, "_", feature)
    
    data
  }

# Equivalent for Seurat objects (taken from Seurat::DimPlot)
direct_feature_access_seurat <- 
  function(object, assay, feature){
    # Include all cells for demo, and use data slot
    cells <- colnames(object)
    slot <- "data" 
    
    data <- 
       sobj@assays[[assay]][[slot]][feature, cells, drop = FALSE]
    
    data <- as.data.frame(data)
    
    colnames(data) <- paste0(Key(object@assays[[assay]]), feature)
    
    data
  }

# Speed test relative to FetchData
# Trials of each function, compared to fetchdata
time <- c()
test <- c()

# FetchData, Seurat objects
results <- 
  repeat_trial(
    func = FetchData, 
    n = 10,
    object = sobj,
    vars = "rna_BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("FetchData_Seurat", 10))

# FetchData, SCE objects
results <- 
  repeat_trial(
    func = FetchData, 
    n = 3,
    object = sce,
    vars = "RNA_BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("FetchData_SCE", 3))

# Direct feature accession, Seurat objects
results <- 
  repeat_trial(
    func = direct_feature_access_seurat, 
    n = 10,
    object = sobj,
    assay = "RNA",
    feature = "BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("Direct_accession_Seurat", 10))

# Direct feature accession, SCE objects
results <- 
  repeat_trial(
    func = direct_feature_access_sce, 
    n = 3,
    object = sce,
    assay = "RNA",
    feature = "BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("Direct_accession_SCE", 3))

direct_acc_v_fetchdata <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time
    )
  )

direct_acc_v_fetchdata$Test <- 
  factor(
    direct_acc_v_fetchdata$Test, 
    levels = 
      c("FetchData_SCE", 
        "Direct_accession_SCE", 
        "FetchData_Seurat",
        "Direct_accession_Seurat" 
        )
    )

plot <- 
  ggplot(data = direct_acc_v_fetchdata, aes(x = Test, y = Time)) +
  geom_boxplot(aes(color = Test)) +
  scale_color_manual(
      values = 
        c("#880000", "#000088", "#008800", "#B8AB2F"),
      aesthetics = "color",
      na.value = "grey50"
      ) + 
  scale_y_continuous(
    breaks = seq(from = 0, to = 30, by = 5),
    limits = c(0, 30)#,
    #labels = function(breaks){paste0(breaks, " s")}
    ) +
  ylab("Time (s)") +
  xlab("Function") +
  theme_cowplot() +
  theme(
    axis.text.x = element_text(size = 9)
    )

plot

ggsave(
  filename = "./Performance_FetchData_vs_direct_accession_features.png",
  plot,
  device = "png",
  bg = "#FFFFFF"
)
```

Direct accession is not faster than FetchData for feature data. The time taken to fetch feature data from SingleCellExperiment objects is much greater than for Seurat objects.

## Alternate Operations to Improve Processing speed

```{r}
### Change block size for data.frame creation
# Create Pointer
pointer <- assays(sce)[["logcounts"]]["BCL2", colnames(sce), drop = FALSE] |> t()

# Block-level apply function for as.data.frame
block_dataframe <- function(x, block_nrow) {
  # 1. Set up the ArrayGrid.
  grid <- rowAutoGrid(x, nrow = block_nrow)
  # 2. Load the blocks into memory and compute the block-level statistics.
  block_level_stat <- blockApply(x, as.data.frame, grid = grid)
  # 3. Combine the block-level statistics.
  unlist(block_level_stat)
}

time <- c()
nrow_block <- c()

# Speed test of block-level as.data.frame function
for (i in c(1000, 5000, 10000, 25000, 50000, 100000, nrow(pointer))){
  tic()
  
  block_dataframe(pointer, i)
  
  suppressMessages(elapsed <- toc())
  
  # Record time elapsed and block size for each trial
  time <- 
    c(time, as.numeric(elapsed$toc - elapsed$tic))
  nrow_block <-
    c(nrow_block, i)
}

block_size_v_time <-
  data.frame(
    list(
    "Block_Size" = nrow_block, 
    "Time" = time
    )
  )

ggplot(data = block_size_v_time, aes(x = Block_Size, y = Time)) +
  geom_point(color = "#000088") +
  scale_y_continuous(
    breaks = seq(from = 0, to = 1000, by = 50)
    ) +
  scale_x_log10(
    breaks = seq(from = 1, to = 200000)#,
    #labels = function(breaks){paste0(breaks, "k")}
  ) +
  ylab("Run Time") +
  xlab("Block Size") +
  theme_cowplot() 
```

# Explore Run time of `scater` plotting functions

Scater is a Bioconductor package for plotting on SingleCellExperiment classes. The performance of the `plotReducedDim` function will be compared to FetchData for the Full AML dataset.

```{r}
#plotReducedDim(sce, dimred = "UMAP", colour_by = "seurat_clusters")

test <- c()
time <- c()

# FetchData, SCE objects
results <- 
  repeat_trial(
    func = FetchData, 
    n = 5,
    object = sce,
    vars = "RNA_BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("FetchData_SCE", 5))

# scater::plotReducedDim
results <- 
  repeat_trial(
    func = scater::plotReducedDim, 
    n = 5,
    object = sce,
    dimred = "UMAP",
    colour_by = "BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("scater::plotReducedDim", 5))

results_df <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time
    )
  )

plot <- 
  ggplot(data = results_df, aes(x = Test, y = Time)) +
  geom_boxplot(aes(color = Test)) +
  scale_color_manual(
      values = 
        c("#430D54", "#3F6326"),
      aesthetics = "color",
      na.value = "grey50"
      ) + 
  scale_y_continuous(
    breaks = seq(from = 25, to = 30, by = 1),
    limits = c(25, 30)#,
    #labels = function(breaks){paste0(breaks, " s")}
    ) +
  ylab("Time (s)") +
  xlab("Function") +
  theme_cowplot() +
  theme(
    axis.text.x = element_text(size = 9)
    )

plot

ggsave(
  filename = "./Performance_FetchData_vs_scater-plotReducedDim.png",
  plot,
  device = "png",
  bg = "#FFFFFF"
)
```

# Are SingleCellExperiment objects faster when saved without compression?

```{r}
nocompression_sce <- loadHDF5SummarizedExperiment("../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_noCompression/")
```

```{r}
test <- c()
time <- c()

# scater::plotReducedDim (object with compression)
results <- 
  repeat_trial(
    func = scater::plotReducedDim, 
    n = 5,
    object = sce,
    dimred = "UMAP",
    colour_by = "BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("scater::plotReducedDim", 5))

# plotReducedDim without compression
results <- 
  repeat_trial(
    func = scater::plotReducedDim, 
    n = 5,
    object = nocompression_sce,
    dimred = "UMAP",
    colour_by = "BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("scater::plotReducedDim_without_sce_compression", 5))


results_df <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time
    )
  )

plot <- 
  ggplot(data = results_df, aes(x = Test, y = Time)) +
  geom_boxplot(aes(color = Test)) +
  scale_color_manual(
      values = 
        c("#82041B", "#430D54"),
      aesthetics = "color",
      na.value = "grey50"
      ) + 
  scale_y_continuous(
    breaks = seq(from = 0, to = 30, by = 5),
    limits = c(0, 30)#,
    #labels = function(breaks){paste0(breaks, " s")}
    ) +
  ylab("Time (s)") +
  xlab("Function") +
  theme_cowplot() +
  theme(
    axis.text.x = element_text(size = 9)
    )

plot

ggsave(
  filename = "./plotReducedDim_compression_v_no_compression.png",
  plot,
  device = "png",
  bg = "#FFFFFF"
)
```

```{r}
test <- c()
time <- c()

# scater::plotReducedDim (object with compression)
results <- 
  repeat_trial(
    func = scater::plotReducedDim, 
    n = 5,
    object = sce,
    dimred = "UMAP",
    colour_by = "BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("scater::plotReducedDim", 5))

# FetchData, SCE object with compression
results <- 
  repeat_trial(
    func = FetchData, 
    n = 5,
    object = sce,
    vars = "RNA_BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("FetchData", 5))

# plotReducedDim without compression
results <- 
  repeat_trial(
    func = scater::plotReducedDim, 
    n = 25,
    object = nocompression_sce,
    dimred = "UMAP",
    colour_by = "BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("scater::plotReducedDim_without_sce_compression", 25))

# FetchData, SCE object with compression
results <- 
  repeat_trial(
    func = FetchData, 
    n = 25,
    object = nocompression_sce,
    vars = "RNA_BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("FetchData_without_sce_compression", 25))


results_df <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time
    )
  )

plot <- 
  ggplot(data = results_df, aes(x = Test, y = Time)) +
  geom_boxplot(aes(color = Test)) +
  scale_color_manual(
      values = 
        c("#82041B", "#224DD2","#430D54", "#377046"),
      aesthetics = "color",
      na.value = "grey50"
      ) +
  scale_y_log10(
    limits = c(0.1, 100)
    ) +
  # scale_y_continuous(
  #   breaks = seq(from = 0, to = 35, by = 5),
  #   limits = c(0, 35)#,
  #   #labels = function(breaks){paste0(breaks, " s")}
  #   ) +
  ylab("Time (s)") +
  xlab("Function") +
  theme_cowplot() +
  theme(
    axis.text.x = element_text(size = 9)
    )

plot

ggsave(
  filename = "./feature_accession_compression_v_no_compression.png",
  plot,
  device = "png",
  bg = "#FFFFFF"
)
```

# How does compression level affect performance?

The speed of data access for SingleCellExperiment objects saved via `HDF5Array::saveHDF5SummarizedExperiment` depends on the compression level chosen when saving to disk. Lower compression levels require more disk space, but allow data to be retrieved more quickly. The speed of data access for each compression level chosen, and for the default compression level, will be assessed below.

```{r}
# Compressed object creation scripts
# DelayedArray::set_verbose_block_processing(TRUE)
# saveHDF5SummarizedExperiment(
#      sce, 
#      dir = "../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_6", 
#      level = 6
#      )
# 
# saveHDF5SummarizedExperiment(
#      sce, 
#      dir = "../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_7/", 
#      level = 7
#      )

# Takes too long to run
# saveHDF5SummarizedExperiment(
#      sce, 
#      dir = "../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_8/", 
#      level = 8
#      )
# 
# saveHDF5SummarizedExperiment(
#      sce, 
#      dir = "../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_9/", 
#      level = 9
#      )
```

```{r}
nocompression_sce <- loadHDF5SummarizedExperiment("../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_noCompression/")

test <- c()
time <- c()

# FetchData, SCE object with no compression
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = nocompression_sce,
    vars = "RNA_BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("0", 100))

sce_level_1 <- loadHDF5SummarizedExperiment("../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_1/")

# FetchData, SCE object with compression level 1
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_level_1,
    vars = "RNA_BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("1", 100))

rm(sce_level_1)

sce_level_2 <- loadHDF5SummarizedExperiment("../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_2/")

# FetchData, SCE object with compression level 2
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_level_2,
    vars = "RNA_BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("2", 100))

rm(sce_level_2)

sce_level_3 <- loadHDF5SummarizedExperiment("../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_3/")

# FetchData, SCE object with compression level 3
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_level_3,
    vars = "RNA_BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("3", 100))

rm(sce_level_3)

sce_level_4 <- loadHDF5SummarizedExperiment("../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_4/")

# FetchData, SCE object with compression level 4
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_level_4,
    vars = "RNA_BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("4", 100))

rm(sce_level_4)

sce_level_5 <- loadHDF5SummarizedExperiment("../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_5/")

# FetchData, SCE object with compression level 5
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_level_5,
    vars = "RNA_BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("5", 100))

rm(sce_level_5)

sce_level_6 <- loadHDF5SummarizedExperiment("../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_6/")

# FetchData, SCE object with compression level 6
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_level_6,
    vars = "RNA_BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("6", 100))

rm(sce_level_6)

sce_level_7 <- loadHDF5SummarizedExperiment("../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_7/")

# FetchData, SCE object with compression level 7
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_level_7,
    vars = "RNA_BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("7", 100))

rm(sce_level_7)

sce <- 
  loadHDF5SummarizedExperiment("../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce/")

# FetchData, SCE object with default compression
results <- 
  repeat_trial(
    func = FetchData, 
    n = 3,
    object = sce,
    vars = "RNA_BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("Default_Compression", 3))

results_df <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time
    )
  )

plot <- 
  ggplot(data = results_df, aes(x = Test, y = Time)) +
  geom_boxplot(aes(color = Test)) +
  scale_color_manual(
      values = ggsci::pal_aaas("default")(9),
      aesthetics = "color",
      na.value = "grey50"
      ) +
  scale_y_log10(
    limits = c(0.1, 100)
    ) +
  # scale_y_continuous(
  #   breaks = seq(from = 0, to = 35, by = 5),
  #   limits = c(0, 35)#,
  #   #labels = function(breaks){paste0(breaks, " s")}
  #   ) +
  ylab("Time (s)") +
  xlab("Compression_Level") +
  labs(
    title = "Expression Data Retrieval Time",
    subtitle = "(One feature from a SingleCellExperiment Object, 200k Cells x 29k Genes)"
  ) +
  theme_cowplot() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 18),
    plot.subtitle = element_text(hjust = 0.5),
    axis.text.x = element_text(size = 9)
    )

plot

ggsave(
  filename = "./speed_by_compression.png",
  plot,
  device = "png",
  bg = "#FFFFFF"
)
```

## Size of SCE objects at different levels of compression

```{r}
directory_size <-
  function(directory){
    file_size <- c()

    # Store size of each file in the directory
    for (file in list.files(directory)){
      file_size <- 
        c(file_size,
          file.info(paste0(directory, file))$size
          )
    }
  
    # Return the total file size
    sum(file_size)
  }

# Store file size for each compression level
sce_size <-
  c(
    directory_size(
      "../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_noCompression/"
      ),
    directory_size(
      "../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_1/"
      ),
    directory_size(
      "../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_2/"
      ),
    directory_size(
      "../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_3/"
      ),
    directory_size(
      "../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_4/"
      ),
    directory_size(
      "../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_5/"
      ),
    directory_size(
      "../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_6/"
      ),
    directory_size(
      "../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce_compression_7/"
      ),
    directory_size(
      "../scExploreR_files/Testing/Full_AML_Downsampled/full_combined_20230207v1_sce/"
    )
  )

compression_level <-
  c(
    "0",
    "1",
    "2",
    "3",
    "4",
    "5",
    "6",
    "7",
    "Default"
  )

size_df <-
  data.frame(
    list(
    "Compression_Level" = compression_level, 
    "Size_on_disk" = sce_size
    )
  )

plot <- 
  ggplot(data = size_df, aes(x = compression_level, y = sce_size/1e+9)) +
  geom_point(color = "#002F99", size = 2.5) +
  scale_y_log10(
    limits = c(8, 100),
    labels = function(breaks){paste0(breaks, " GB")}
    ) +
  ylab("Size on Disk") +
  xlab("Compression Level") +
  ggtitle("Size of SingleCellExperiment Object on Disk (200k Cells x 29k Genes)") +
  theme_cowplot() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

plot

ggsave(
  filename = "./size_by_compression.png",
  plot,
  device = "png",
  bg = "#FFFFFF"
)
```

Based on these results, compression level 3 should be used for HDF5-enabled SingleCellExperiment objects.

# How does FetchData Scale with Additional Features?

The tests below will be performed on an object with compression level 3.

```{r}
test <- c()
time <- c()

# FetchData, one feature
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_3,
    vars = "RNA_BCL2"
    )

time <- c(time, results)
test <- c(test, rep_len("1", 100))

# FetchData, two features
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_3,
    vars = c("RNA_BCL2", "RNA_MEN1")
    )

time <- c(time, results)
test <- c(test, rep_len("2", 100))

# FetchData, three features
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_3,
    vars = c("RNA_BCL2", "RNA_MEN1", "RNA_MEIS1")
    )

time <- c(time, results)
test <- c(test, rep_len("3", 100))

# FetchData, four features
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_3,
    vars = c("RNA_BCL2", "RNA_MEN1", "RNA_MEIS1", "RNA_HOXA9")
    )

time <- c(time, results)
test <- c(test, rep_len("4", 100))

# FetchData, five features
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_3,
    vars = c("RNA_BCL2", "RNA_MEN1", "RNA_MEIS1", "RNA_HOXA9", "RNA_FIS1")
    )

time <- c(time, results)
test <- c(test, rep_len("5", 100))

# FetchData, six features
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_3,
    vars = c("RNA_BCL2", "RNA_MEN1", "RNA_MEIS1", "RNA_HOXA9", "RNA_FIS1", "RNA_MCL1")
    )

time <- c(time, results)
test <- c(test, rep_len("6", 100))

# FetchData, seven features
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_3,
    vars = c("RNA_BCL2", "RNA_MEN1", "RNA_MEIS1", "RNA_HOXA9", "RNA_FIS1", "RNA_MCL1", "RNA_SIRT2")
    )

time <- c(time, results)
test <- c(test, rep_len("7", 100))

# FetchData, eight features
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_3,
    vars = c("RNA_BCL2", "RNA_MEN1", "RNA_MEIS1", "RNA_HOXA9", "RNA_FIS1", "RNA_MCL1", "RNA_SIRT2", "RNA_HIF1A")
    )

time <- c(time, results)
test <- c(test, rep_len("8", 100))

# FetchData, nine features
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_3,
    vars = c("RNA_BCL2", "RNA_MEN1", "RNA_MEIS1", "RNA_HOXA9", "RNA_FIS1", "RNA_MCL1", "RNA_SIRT2", "RNA_HIF1A", "RNA_HOXA10")
    )

time <- c(time, results)
test <- c(test, rep_len("9", 100))

# FetchData, ten features
results <- 
  repeat_trial(
    func = FetchData, 
    n = 100,
    object = sce_3,
    vars = c("RNA_BCL2", "RNA_MEN1", "RNA_MEIS1", "RNA_HOXA9", "RNA_FIS1", 
             "RNA_MCL1", "RNA_SIRT2", "RNA_HIF1A", "RNA_HOXA10", "RNA_FOXO1")
    )

time <- c(time, results)
test <- c(test, rep_len("10", 100))

results_df <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time
    )
  )

results_df$Test <-
  factor(
    results_df$Test, 
    levels = 
      str_sort(
        results_df$Test |> unique(), 
        numeric = TRUE
        )
    )

plot <- 
  ggplot(data = results_df, aes(x = Test, y = Time)) +
  geom_boxplot(aes(color = Test)) +
  scale_color_manual(
      values = ggsci::pal_aaas("default")(10),
      aesthetics = "color",
      na.value = "grey50"
      ) +
  scale_y_continuous(
    breaks = seq(from = 0, to = 2.4, by = 0.2),
    limits = c(0, 2.4)#,
    #labels = function(breaks){paste0(breaks, " s")}
    ) +
  ylab("Time (s)") +
  xlab("Number of Features") +
  labs(
    title = "Expression Data Retrieval Time",
    subtitle = 
      "(SingleCellExperiment Object, 200k Cells x 29k Genes, HDF5Array Compression Level 3)"
  ) +
  guides(
    color = 
      guide_legend(
        title = NULL
        )
  ) +
  theme_cowplot() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 18),
    plot.subtitle = element_text(hjust = 0.5),
    axis.text.x = element_text(size = 9)
    )

plot

ggsave(
  filename = "./speed_by_n_features.png",
  plot,
  device = "png",
  bg = "#FFFFFF"
)
```

## How Does Retrieval Time by Feature Compare to FetchData for Seurat Objects?

## Is direct accession of expression data more scalable than FetchData?

```{r}
# Trials of each function, compared to fetchdata
time <- c()
test <- c()
n_features <- c()

meta_colname <- "leiden_clusters"

#cells_sobj <- get_all_cells(sobj)
cells_sce <- get_all_cells(sce_3)

# Direct accession function
direct_feature_access_sce <- 
  function(object, assay, feature){
    # Inlcude all cells in demo, and use logcounts slot
    cells <- colnames(object)
    slot <- "logcounts"

    exp_use <- 
      if (assay %in% altExpNames(object)){
        altExps(object)[[assay]]
      } else {
        object
      }
    
    # data <-
    #   assays(exp_use)[[slot]][feature, cells, drop = FALSE] |>
    #   as.matrix() |>
    #   t()
    data <- assays(exp_use)[[slot]][feature, cells, drop = FALSE] |> t()
    
    data <- as.data.frame(data)
    
    colnames(data) <- paste0(assay, "_", feature)
    
    data
  }

# Greatest amount of n_features to include while testing
max_n_features <- 20
# FetchData, SCE objects
for (i in 1:max_n_features){
  cat("FetchData on SCE object, n_features =", i, "\n")
  # Select features (randomly, n = i)
  features <- rownames(sce_3)[sample(1:nrow(sce_3), i)]
  trials <- 20
  trial_name <- "FetchData_SCE"
  
  # Trial for n_features == i
  results <- 
    repeat_trial(
      func = FetchData, 
      n = trials,
      object = sce_3,
      vars = features
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  # Record number of features for the trial (as character)
  n_features <- 
    c(n_features, 
      rep_len(
        as.character(i), 
        trials
        )
      )
}

# fetch_metadata, SCE object
for (i in 1:max_n_features){
  cat("direct_feature_access on SCE object, n_features =", i, "\n")
  # Select features (randomly, n = i)
  features <- rownames(sce_3)[sample(1:nrow(sce_3), i)]
  trials <- 20
  trial_name <- "direct_feature_access_SCE"
  
  # Trial for n_features == i
  results <- 
    repeat_trial(
      func = direct_feature_access_sce, 
      n = trials,
      object = sce_3,
      assay = "logcounts",
      feature = features
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  # Record number of features for the trial (as character)
  n_features <- 
    c(n_features, 
      rep_len(
        as.character(i), 
        trials
        )
      )
}

results_df <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time,
    "Features" = n_features
    )
  )

results_df$Features <-
  factor(
    results_df$Features, 
    levels = 
      str_sort(
        results_df$Features |> unique(), 
        numeric = TRUE
        )
    )

# Boxplot
# plot <- 
#   ggplot(data = results_df, aes(x = Features, y = Time)) +
#   geom_boxplot(aes(color = Test)) +
#   scale_color_manual(
#       values = ggsci::pal_aaas("default")(10)[c(1,5)],
#       aesthetics = "color",
#       na.value = "grey50"
#       ) +
#   scale_y_log10(
#     limits = c(0.1, 10)
#   ) +
#   # scale_y_continuous(
#   #   breaks = seq(from = 0, to = 0.5, by = 0.05),
#   #   limits = c(0, 0.5)#,
#   #   #labels = function(breaks){paste0(breaks, " s")}
#   #   ) +
#   ylab("Time (s)") +
#   xlab("Number of Features") +
#   labs(
#     title = "Expression Data Retrieval Time",
#     subtitle = 
#       "(SingleCellExperiment Object, 200k Cells x 29k Genes, HDF5Array Compression Level 3)"
#   ) +
#   guides(
#     color = 
#       guide_legend(
#         title = NULL
#         )
#   ) +
#   theme_cowplot() +
#   theme(
#     plot.title = element_text(hjust = 0.5, size = 18),
#     plot.subtitle = element_text(hjust = 0.5),
#     axis.text.x = element_text(size = 9)
#     )

#plot

# Scatterplot with error bars
# Create summary stats for results
summary_df <- 
  results_df |> 
  group_by(Test, Features) |> 
  summarize(
    mean_time = mean(Time),
    sd = sd(Time)
  )

plot <-
  ggplot(data = summary_df, aes(x = Features, y = mean_time, color = Test, group = Test)) +
  geom_point() +
  geom_errorbar(aes(ymin = mean_time - sd, ymax = mean_time + sd)) +
  scale_color_manual(
      values = ggsci::pal_aaas("default")(10)[c(1,5)],
      aesthetics = "color",
      na.value = "grey50"
      ) +
  scale_y_log10(
    limits = c(0.1, 10)
  ) +
  # scale_y_continuous(
  #   breaks = seq(from = 0, to = 0.5, by = 0.05),
  #   limits = c(0, 0.5)#,
  #   #labels = function(breaks){paste0(breaks, " s")}
  #   ) +
  ylab("Time (s)") +
  xlab("Number of Features") +
  labs(
    title = "Expression Data Retrieval Time",
    subtitle =
      "(SingleCellExperiment Object, 200k Cells x 29k Genes, HDF5Array Compression Level 3)"
  ) +
  guides(
    color =
      guide_legend(
        title = NULL
        )
  ) +
  theme_cowplot() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 18),
    plot.subtitle = element_text(hjust = 0.5),
    axis.text.x = element_text(size = 9)
    )

plot

ggsave(
  filename = "./fetchData_vs_direct_accession_1-20_features.png",
  plot,
  device = "png",
  bg = "#FFFFFF"
)
```

# Performance comparison of SCEPlots::plot_feature to Seurat::FeaturePlot

```{r}
# Set up data collected from in silico performance test
time <- c()
test <- c()

cells_sobj <- get_all_cells(sobj)
cells_sce <- get_all_cells(sce_3)

cat("plot_feature on Seurat object \n")
# Seed is set before each random feature access so the same random feature 
# is chosen during each trial
set.seed(2023)
# Select features (randomly, n = i)
#features <- rownames(sce_3)[sample(1:nrow(sce_3), i)]
# Select one random feature
features <- rownames(sobj)[sample(1:nrow(sobj), 1)]
trials <- 20
trial_name <- "plot_feature, Seurat Object"

# Trial for n_features == i
results <- 
  repeat_trial(
    func = SCEPlots::plot_feature, 
    n = trials,
    object = sobj,
    features = features
    )

time <- c(time, results)
test <- c(test, rep_len(trial_name, trials))



cat("Seurat::FeaturePlot on Seurat object \n")
set.seed(2023)
# Select features (randomly, n = i)
#features <- rownames(sce_3)[sample(1:nrow(sce_3), i)]
# Select one random feature
features <- rownames(sobj)[sample(1:nrow(sobj), 1)]
trials <- 20
trial_name <- "FeaturePlot, Seurat Object"

# Trial for n_features == i
results <- 
  repeat_trial(
    func = Seurat::FeaturePlot, 
    n = trials,
    object = sobj,
    features = features
    )

time <- c(time, results)
test <- c(test, rep_len(trial_name, trials))

cat("plot_feature on SCE object \n")
set.seed(2023)
# Select features (randomly, n = i)
#features <- rownames(sce_3)[sample(1:nrow(sce_3), i)]
# Select one random feature
features <- rownames(sce_3)[sample(1:nrow(sce_3), 1)]
trials <- 20
trial_name <- "plot_feature, SCE Object"

# Trial for n_features == i
results <- 
  repeat_trial(
    func = SCEPlots::plot_feature, 
    n = trials,
    object = sce_3,
    features = features
    )

time <- c(time, results)
test <- c(test, rep_len(trial_name, trials))

performance_results <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time
    )
  )

performance_results$Test <- 
  factor(
    performance_results$Test, 
    levels = 
      c("FeaturePlot, Seurat Object",
        "plot_feature, Seurat Object",
        "plot_feature, SCE Object"
        )
    )

plot <- 
  ggplot(data = performance_results, aes(x = Test, y = Time)) +
  geom_boxplot(aes(color = Test)) +
  scale_color_manual(
      values = 
        ggsci::pal_aaas("default")(10)[c(1,4,3)],
      aesthetics = "color",
      na.value = "grey50"
      ) + 
  scale_y_continuous(
    breaks = seq(from = 0, to = 30, by = 5),
    limits = c(0, 12)#,
    #labels = function(breaks){paste0(breaks, " s")}
    ) +
  ylab("Time (s)") +
  xlab("Function") +
  theme_cowplot() +
  theme(
    axis.text.x = element_text(size = 9)
    )

plot

# ggsave(
#   filename = "./Performance_plot_feature_vs_feature_plot.png",
#   plot,
#   device = "png",
#   bg = "#FFFFFF"
# )
```

## How does plot_feature scale with the number of features?

```{r}
time <- c()
test <- c()
n_features <- c()

cells_sobj <- get_all_cells(sobj)
cells_sce <- get_all_cells(sce_3)

# Greatest amount of n_features to include while testing
max_n_features <- 10

# Seed is set before each random feature access so the same "random" features
# are chosen during each trial
set.seed(2023)
# plot_feature, Seurat object
for (i in 1:max_n_features){
  cat("plot_feature on Seurat object, n_features =", i, "\n")
  # Select features (randomly, n = i)
  features <- rownames(sobj)[sample(1:nrow(sobj), i)]
  trials <- 5
  trial_name <- "plot_feature, Seurat Object"
  
  # Trial for n_features == i
  results <- 
    repeat_trial(
      func = SCEPlots::plot_feature, 
      n = trials,
      object = sobj,
      features = features
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  # Record number of features for the trial (as character)
  n_features <- 
    c(n_features, 
      rep_len(
        as.character(i), 
        trials
        )
      )
}

# FeaturePlot, Seurat object
set.seed(2023)
for (i in 1:max_n_features){
  cat("FeaturePlot on Seurat object, n_features =", i, "\n")
  # Select features (randomly, n = i)
  features <- rownames(sobj)[sample(1:nrow(sobj), i)]
  trials <- 5
  trial_name <- "FeaturePlot, Seurat Object"
  
  # Trial for n_features == i
  results <- 
    repeat_trial(
      func = Seurat::FeaturePlot, 
      n = trials,
      object = sobj,
      features = features
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  # Record number of features for the trial (as character)
  n_features <- 
    c(n_features, 
      rep_len(
        as.character(i), 
        trials
        )
      )
}

# plot_feature, SCE object
set.seed(2023)
for (i in 1:max_n_features){
  cat("plot_feature on SCE object, n_features =", i, "\n")
  # Select features (randomly, n = i)
  features <- rownames(sce_3)[sample(1:nrow(sce_3), i)]
  trials <- 10
  trial_name <- "plot_feature, SCE Object"
  
  # Trial for n_features == i
  results <- 
    repeat_trial(
      func = SCEPlots::plot_feature, 
      n = trials,
      object = sce_3,
      features = features
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  # Record number of features for the trial (as character)
  n_features <- 
    c(n_features, 
      rep_len(
        as.character(i), 
        trials
        )
      )
}

results_df <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time,
    "Features" = n_features
    )
  )

results_df$Features <-
  factor(
    results_df$Features, 
    levels = 
      str_sort(
        results_df$Features |> unique(), 
        numeric = TRUE
        )
    )

results_df$Test <- 
  factor(
    results_df$Test, 
    levels = 
      c("FeaturePlot, Seurat Object",
        "plot_feature, Seurat Object",
        "plot_feature, SCE Object"
        )
    )

# Scatterplot with error bars
# Create summary stats for results
summary_df <- 
  results_df |> 
  group_by(Test, Features) |> 
  summarize(
    mean_time = mean(Time),
    sd = sd(Time)
  )

plot <-
  ggplot(data = summary_df, aes(x = Features, y = mean_time, color = Test, group = Test)) +
  geom_point() +
  geom_errorbar(aes(ymin = mean_time - sd, ymax = mean_time + sd)) +
  scale_color_manual(
      values = ggsci::pal_aaas("default")(10)[c(3,6,7)],
      aesthetics = "color",
      na.value = "grey50"
      ) +
  scale_y_continuous(
    limits = c(0, 9)
  ) +
  # scale_y_continuous(
  #   breaks = seq(from = 0, to = 0.5, by = 0.05),
  #   limits = c(0, 0.5)#,
  #   #labels = function(breaks){paste0(breaks, " s")}
  #   ) +
  ylab("Time (s)") +
  xlab("Number of Features") +
  labs(
    title = "Feature Plot Performance",
    subtitle =
      "(200k Cells x 29k Genes, HDF5Array Compression Level 3 for SCE objects)"
  ) +
  guides(
    color =
      guide_legend(
        title = NULL
        )
  ) +
  theme_cowplot() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 18),
    plot.subtitle = element_text(hjust = 0.5),
    axis.text.x = element_text(size = 9)
    )

plot

ggsave(
  filename = "./plot_feature_vs_FeaturePlot_1-10_features.png",
  plot,
  device = "png",
  bg = "#FFFFFF"
)
```

## How does plot_feature scale with the number of splits?

```{r}
time <- c()
test <- c()
n_splits <- c()

cells_sobj <- get_all_cells(sobj)
cells_sce <- get_all_cells(sce_3)

# Metadata to create split plots from
test_metadata <- c(
  "cell_call",
  "Phase",
  "HTO_classification",
  "sample_id",
  "aml_id",
  "htb_id",
  "best_response",
  "specimen_type",
  "sample_type",
  "note",
  "seurat_clusters",
  "leiden_clusters_char",
  "leiden_clusters_char_lngb",
  "ab200_clusters",
  "ab200_clusters_lngb",
  "velten_clusters"
  )

# Seed is set before each random feature access so the same "random" features
# are chosen during each trial
set.seed(2023)
# plot_feature, Seurat object
for (i in 1:length(test_metadata)){
  meta_i <- test_metadata[i]
  cat(
    "plot_feature on Seurat object, metadata col ", 
    i, 
    "/",
    length(test_metadata),
    "\n",
    "(Number of splits: ",
    length(unique(sobj@meta.data[[test_metadata[i]]])),
    ")",
    "\n",
    sep = ""
    )
  # Select random feature
  features <- rownames(sobj)[sample(1:nrow(sobj), 1)]
  trials <- 3
  trial_name <- "plot_feature, Seurat Object"
  
  # Trial for n_features == i
  results <- 
    repeat_trial(
      func = SCEPlots::plot_feature, 
      n = trials,
      object = sobj,
      features = features,
      split_by = meta_i
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  
  # Record number of splits for trial i
  n_splits_i <-
    sobj@meta.data[[meta_i]] |>
          unique() |> 
          length()
  
  n_splits <- 
    c(n_splits, 
      rep_len(
        n_splits_i, 
        trials
        )
      )
}

# FeaturePlot, Seurat object
set.seed(2023)
for (i in 1:length(test_metadata)){
  meta_i <- test_metadata[i]
  cat(
    "FeaturePlot on Seurat object, metadata col ", 
    i, 
    "/",
    length(test_metadata),
    "\n",
    "(Number of splits: ",
    length(unique(sobj@meta.data[[test_metadata[i]]])),
    ")",
    "\n",
    sep = ""
    )
  # Select random feature
  features <- rownames(sobj)[sample(1:nrow(sobj), 1)]
  trials <- 3
  trial_name <- "FeaturePlot, Seurat Object"
  
  # Trial
  results <- 
    results <- 
    repeat_trial(
      func = Seurat::FeaturePlot, 
      n = trials,
      object = sobj,
      features = features,
      split.by = meta_i
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  
  # Record number of splits for trial i
  n_splits_i <-
    sobj@meta.data[[meta_i]] |>
          unique() |> 
          length()
  
  n_splits <- 
    c(n_splits, 
      rep_len(
        n_splits_i, 
        trials
        )
      )
}

# plot_feature, SCE object
set.seed(2023)
for (i in 1:length(test_metadata)){
  meta_i <- test_metadata[i]
  cat(
    "plot_feature on SCE object, metadata col ", 
    i, 
    "/",
    length(test_metadata),
    "\n",
    "(Number of splits: ",
    length(unique(colData(sce_3)[[test_metadata[i]]])),
    ")",
    "\n",
    sep = ""
    )
  # Select random feature
  features <- rownames(sce_3)[sample(1:nrow(sce_3), 1)]
  trials <- 3
  trial_name <- "plot_feature, SCE Object"
  
  # Trial
  results <- 
    repeat_trial(
      func = SCEPlots::plot_feature, 
      n = trials,
      object = sce_3,
      features = features,
      split_by = meta_i
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  
  # Record number of splits for trial i
  n_splits_i <-
    sobj@meta.data[[meta_i]] |>
          unique() |> 
          length()
  
  n_splits <- 
    c(n_splits, 
      rep_len(
        n_splits_i, 
        trials
        )
      )
}

results_df <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time,
    "Splits" = n_splits
    )
  )

# results_df$Splits <-
#   factor(
#     results_df$Splits, 
#     )

results_df$Test <-
  factor(
    results_df$Test,
    levels =
      c("FeaturePlot, Seurat Object",
        "plot_feature, Seurat Object",
        "plot_feature, SCE Object"
        )
    )

# Scatterplot with error bars
# Create summary stats for results
summary_df <- 
  results_df |> 
  group_by(Test, Splits) |> 
  summarize(
    mean_time = mean(Time),
    sd = sd(Time)
  )

plot <-
  ggplot(data = summary_df, aes(x = Splits, y = mean_time, color = Test, group = Test)) +
  geom_point() +
  geom_errorbar(aes(ymin = mean_time - sd, ymax = mean_time + sd)) +
  scale_color_manual(
      values = ggsci::pal_aaas("default")(10)[c(3,6,7)],
      aesthetics = "color",
      na.value = "grey50"
      ) +
  # scale_x_continuous(
  #   limits = c(0, 210)
  # ) +
  scale_y_continuous(
    limits = c(0, 40)
  ) +
  # scale_y_log10(
  #   limits = c(0.9, 100)
  # ) +
  ylab("Time (s)") +
  xlab("Number of Splits") +
  labs(
    title = "Feature Plot Performance",
    subtitle =
      "(200k Cells x 29k Genes, HDF5Array Compression Level 3 for SCE objects)"
  ) +
  guides(
    color =
      guide_legend(
        title = NULL
        )
  ) +
  theme_cowplot() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 18),
    plot.subtitle = element_text(hjust = 0.5),
    axis.text.x = element_text(size = 9)
    )

plot

ggsave(
  filename = "./plot_feature_vs_FeaturePlot_splits.png",
  plot,
  device = "png",
  bg = "#FFFFFF"
)
```

```{r}
for (col in colnames(sobj@meta.data)){
  n_unique <- 
    sobj@meta.data[[col]] |> 
      unique() |> 
      length()
  
  if (class(sobj@meta.data[[col]]) %in% c("character", "factor") && n_unique < 205 && n_unique > 1){
    cat('"', col, '": ', sep = "")
    cat(n_unique, '\n', sep = "")
  }
}

c(
  "cell_call",
  "Phase",
  "HTO_classification",
  "sample_id",
  "aml_id",
  "htb_id",
  "best_response",
  "specimen_type",
  "sample_type",
  "note",
  "seurat_clusters",
  "leiden_clusters_char",
  "leiden_clusters_char_lngb",
  "ab200_clusters",
  "ab200_clusters_lngb",
  "velten_clusters"
  ) |> length()
```


# Speed Test of var == TRUE vs. isTRUE(var)

Seurat functions use `isTRUE`, but this is slightly slower than `== TRUE`.
```{r}
time <- c()
test <- c()

true_var <- TRUE

trials <- 100
trial_name <- "isTRUE"
  
is_true <- 
  function(var){
    for (i in 1:100000){
      isTRUE(var)
    }
  }

# Trial for n_features == i
results <- 
  repeat_trial(
    func = is_true, 
    n = trials,
    var = true_var
    )

time <- c(time, results)
test <- c(test, rep_len(trial_name, trials))

trial_name <- "EqualsTrue"

equalsTrue <- function(var){
  for (i in 1:100000){
    var == TRUE
    }
  }

# Trial for n_features == i
results <- 
  repeat_trial(
    func = equalsTrue, 
    n = trials,
    var = true_var
    )

time <- c(time, results)
test <- c(test, rep_len(trial_name, trials))

results_df <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time
    )
  )

plot <- 
  ggplot(data = results_df, aes(x = Test, y = Time)) +
  geom_boxplot(aes(color = Test)) +
  scale_color_manual(
      values = 
        c("#880000", "#000088"),
      aesthetics = "color",
      na.value = "grey50"
      ) + 
  scale_y_continuous(
    limits = c(0, 0.5)#,
    #labels = function(breaks){paste0(breaks, " s")}
    ) +
  ylab("Time (s)") +
  xlab("Function") +
  theme_cowplot() +
  theme(
    axis.text.x = element_text(size = 9)
    )

plot
```

# How do plot_violin and plot_ridge scale with number of features?
## plot_violin

```{r}
time <- c()
test <- c()
n_features <- c()

cells_sobj <- get_all_cells(sobj)
cells_sce <- get_all_cells(sce_3)

# Greatest amount of n_features to include while testing
max_n_features <- 10

# Seed is set before each random feature access so the same "random" features
# are chosen during each trial
set.seed(2023)
# plot_feature, Seurat object
for (i in 1:max_n_features){
  cat("plot_violin on Seurat object, n_features =", i, "\n")
  # Select features (randomly, n = i)
  features <- rownames(sobj)[sample(1:nrow(sobj), i)]
  trials <- 5
  trial_name <- "plot_violin, Seurat Object"
  
  # Trial for n_features == i
  results <- 
    repeat_trial(
      func = SCEPlots::plot_violin, 
      n = trials,
      object = sobj,
      features = features,
      group_by = "rochester"
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  # Record number of features for the trial (as character)
  n_features <- 
    c(n_features, 
      rep_len(
        as.character(i), 
        trials
        )
      )
}

# FeaturePlot, Seurat object
set.seed(2023)
for (i in 1:max_n_features){
  cat("VlnPlot on Seurat object, n_features =", i, "\n")
  # Select features (randomly, n = i)
  features <- rownames(sobj)[sample(1:nrow(sobj), i)]
  trials <- 5
  trial_name <- "VlnPlot, Seurat Object"
  
  # Trial for n_features == i
  results <- 
    repeat_trial(
      func = Seurat::VlnPlot, 
      n = trials,
      object = sobj,
      features = features,
      group.by = "rochester"
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  # Record number of features for the trial (as character)
  n_features <- 
    c(n_features, 
      rep_len(
        as.character(i), 
        trials
        )
      )
}

# plot_feature, SCE object
set.seed(2023)
for (i in 1:max_n_features){
  cat("plot_violin on SCE object, n_features =", i, "\n")
  # Select features (randomly, n = i)
  features <- rownames(sce_3)[sample(1:nrow(sce_3), i)]
  trials <- 5
  trial_name <- "plot_violin, SCE Object"
  
  # Trial for n_features == i
  results <- 
    repeat_trial(
      func = SCEPlots::plot_violin, 
      n = trials,
      object = sce_3,
      features = features,
      group_by = "rochester"
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  # Record number of features for the trial (as character)
  n_features <- 
    c(n_features, 
      rep_len(
        as.character(i), 
        trials
        )
      )
}

results_df <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time,
    "Features" = n_features
    )
  )

results_df$Features <-
  factor(
    results_df$Features, 
    levels = 
      str_sort(
        results_df$Features |> unique(), 
        numeric = TRUE
        )
    )

results_df$Test <- 
  factor(
    results_df$Test, 
    levels = 
      c("VlnPlot, Seurat Object",
        "plot_violin, Seurat Object",
        "plot_violin, SCE Object"
        )
    )

# Scatterplot with error bars
# Create summary stats for results
summary_df <- 
  results_df |> 
  group_by(Test, Features) |> 
  summarize(
    mean_time = mean(Time),
    sd = sd(Time)
  )

plot <-
  ggplot(data = summary_df, aes(x = Features, y = mean_time, color = Test, group = Test)) +
  geom_point() +
  geom_errorbar(aes(ymin = mean_time - sd, ymax = mean_time + sd)) +
  scale_color_manual(
      values = ggsci::pal_aaas("default")(10)[c(3,6,7)],
      aesthetics = "color",
      na.value = "grey50"
      ) +
  scale_y_continuous(
    limits = c(0, 5)
  ) +
  # scale_y_continuous(
  #   breaks = seq(from = 0, to = 0.5, by = 0.05),
  #   limits = c(0, 0.5)#,
  #   #labels = function(breaks){paste0(breaks, " s")}
  #   ) +
  ylab("Time (s)") +
  xlab("Number of Features") +
  labs(
    title = "Violin Plot Performance",
    subtitle =
      "(200k Cells x 29k Genes, HDF5Array Compression Level 3 for SCE objects)"
  ) +
  guides(
    color =
      guide_legend(
        title = NULL
        )
  ) +
  theme_cowplot() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 18),
    plot.subtitle = element_text(hjust = 0.5),
    axis.text.x = element_text(size = 9)
    )

plot

ggsave(
  filename = "./plot_violin_vs_VlnPlot_1-10_features.png",
  plot,
  device = "png",
  bg = "#FFFFFF"
)
```

## plot_ridge

```{r}
time <- c()
test <- c()
n_features <- c()

# Greatest amount of n_features to include while testing
max_n_features <- 10

# Seed is set before each random feature access so the same "random" features
# are chosen during each trial
set.seed(2023)
# plot_feature, Seurat object
for (i in 1:max_n_features){
  cat("plot_ridge on Seurat object, n_features =", i, "\n")
  # Select features (randomly, n = i)
  features <- rownames(sobj)[sample(1:nrow(sobj), i)]
  trials <- 5
  trial_name <- "plot_ridge, Seurat Object"
  
  # Trial for n_features == i
  results <- 
    repeat_trial(
      func = SCEPlots::plot_ridge, 
      n = trials,
      object = sobj,
      features = features,
      group_by = "rochester"
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  # Record number of features for the trial (as character)
  n_features <- 
    c(n_features, 
      rep_len(
        as.character(i), 
        trials
        )
      )
}

# FeaturePlot, Seurat object
set.seed(2023)
for (i in 1:max_n_features){
  cat("RidgePlot on Seurat object, n_features =", i, "\n")
  # Select features (randomly, n = i)
  features <- rownames(sobj)[sample(1:nrow(sobj), i)]
  trials <- 5
  trial_name <- "RidgePlot, Seurat Object"
  
  # Trial for n_features == i
  results <- 
    repeat_trial(
      func = Seurat::RidgePlot, 
      n = trials,
      object = sobj,
      features = features,
      group.by = "rochester"
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  # Record number of features for the trial (as character)
  n_features <- 
    c(n_features, 
      rep_len(
        as.character(i), 
        trials
        )
      )
}

# plot_feature, SCE object
set.seed(2023)
for (i in 1:max_n_features){
  cat("plot_ridge on SCE object, n_features =", i, "\n")
  # Select features (randomly, n = i)
  features <- rownames(sce_3)[sample(1:nrow(sce_3), i)]
  trials <- 5
  trial_name <- "plot_ridge, SCE Object"
  
  # Trial for n_features == i
  results <- 
    repeat_trial(
      func = SCEPlots::plot_ridge, 
      n = trials,
      object = sce_3,
      features = features,
      group_by = "rochester"
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  # Record number of features for the trial (as character)
  n_features <- 
    c(n_features, 
      rep_len(
        as.character(i), 
        trials
        )
      )
}

results_df <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time,
    "Features" = n_features
    )
  )

results_df$Features <-
  factor(
    results_df$Features, 
    levels = 
      str_sort(
        results_df$Features |> unique(), 
        numeric = TRUE
        )
    )

results_df$Test <- 
  factor(
    results_df$Test, 
    levels = 
      c("RidgePlot, Seurat Object",
        "plot_ridge, Seurat Object",
        "plot_ridge, SCE Object"
        )
    )

# Scatterplot with error bars
# Create summary stats for results
summary_df <- 
  results_df |> 
  group_by(Test, Features) |> 
  summarize(
    mean_time = mean(Time),
    sd = sd(Time)
  )

plot <-
  ggplot(data = summary_df, aes(x = Features, y = mean_time, color = Test, group = Test)) +
  geom_point() +
  geom_errorbar(aes(ymin = mean_time - sd, ymax = mean_time + sd)) +
  scale_color_manual(
      values = ggsci::pal_aaas("default")(10)[c(3,6,7)],
      aesthetics = "color",
      na.value = "grey50"
      ) +
  scale_y_continuous(
    limits = c(0, 5)
  ) +
  # scale_y_continuous(
  #   breaks = seq(from = 0, to = 0.5, by = 0.05),
  #   limits = c(0, 0.5)#,
  #   #labels = function(breaks){paste0(breaks, " s")}
  #   ) +
  ylab("Time (s)") +
  xlab("Number of Features") +
  labs(
    title = "Ridge Plot Performance",
    subtitle =
      "(200k Cells x 29k Genes, HDF5Array Compression Level 3 for SCE objects)"
  ) +
  guides(
    color =
      guide_legend(
        title = NULL
        )
  ) +
  theme_cowplot() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 18),
    plot.subtitle = element_text(hjust = 0.5),
    axis.text.x = element_text(size = 9)
    )

plot

ggsave(
  filename = "./plot_ridge_vs_RidgePlot_1-10_features.png",
  plot,
  device = "png",
  bg = "#FFFFFF"
)
```

# How does plot_dot scale with the number of features, compared to Seruat::DotPlot()?

```{r}
time <- c()
test <- c()
n_features <- c()

# Greatest amount of n_features to include while testing
max_n_features <- 10

# Seed is set before each random feature access so the same "random" features
# are chosen during each trial
set.seed(2023)
# plot_feature, Seurat object
for (i in 1:max_n_features){
  cat("plot_dot on Seurat object, n_features =", i, "\n")
  # Select features (randomly, n = i)
  features <- rownames(sobj)[sample(1:nrow(sobj), i)]
  trials <- 25
  trial_name <- "plot_dot, Seurat Object"
  
  # Trial for n_features == i
  results <- 
    repeat_trial(
      func = SCEPlots::plot_dot, 
      n = trials,
      object = sobj,
      features = features,
      group_by = "ab200_clusters"
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  # Record number of features for the trial (as character)
  n_features <- 
    c(n_features, 
      rep_len(
        as.character(i), 
        trials
        )
      )
}

# FeaturePlot, Seurat object
set.seed(2023)
for (i in 1:max_n_features){
  cat("DotPlot on Seurat object, n_features =", i, "\n")
  # Select features (randomly, n = i)
  features <- rownames(sobj)[sample(1:nrow(sobj), i)]
  trials <- 25
  trial_name <- "DotPlot, Seurat Object"
  
  # Trial for n_features == i
  results <- 
    repeat_trial(
      func = Seurat::DotPlot, 
      n = trials,
      object = sobj,
      features = features,
      group.by = "ab200_clusters"
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  # Record number of features for the trial (as character)
  n_features <- 
    c(n_features, 
      rep_len(
        as.character(i), 
        trials
        )
      )
}

# plot_feature, SCE object
set.seed(2023)
for (i in 1:max_n_features){
  cat("plot_dot on SCE object, n_features =", i, "\n")
  # Select features (randomly, n = i)
  features <- rownames(sce_3)[sample(1:nrow(sce_3), i)]
  trials <- 25
  trial_name <- "plot_dot, SCE Object"
  
  # Trial for n_features == i
  results <- 
    repeat_trial(
      func = SCEPlots::plot_dot, 
      n = trials,
      object = sce_3,
      features = features,
      group_by = "ab200_clusters"
      )
  
  time <- c(time, results)
  test <- c(test, rep_len(trial_name, trials))
  # Record number of features for the trial (as character)
  n_features <- 
    c(n_features, 
      rep_len(
        as.character(i), 
        trials
        )
      )
}

results_df <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time,
    "Features" = n_features
    )
  )

results_df$Features <-
  factor(
    results_df$Features, 
    levels = 
      str_sort(
        results_df$Features |> unique(), 
        numeric = TRUE
        )
    )

results_df$Test <- 
  factor(
    results_df$Test, 
    levels = 
      c("DotPlot, Seurat Object",
        "plot_dot, Seurat Object",
        "plot_dot, SCE Object"
        )
    )

# Scatterplot with error bars
# Create summary stats for results
summary_df <- 
  results_df |> 
  group_by(Test, Features) |> 
  summarize(
    mean_time = mean(Time),
    sd = sd(Time)
  )

plot <-
  ggplot(data = summary_df, aes(x = Features, y = mean_time, color = Test, group = Test)) +
  geom_point() +
  geom_errorbar(aes(ymin = mean_time - sd, ymax = mean_time + sd)) +
  scale_color_manual(
      values = ggsci::pal_aaas("default")(10)[c(3,6,7)],
      aesthetics = "color",
      na.value = "grey50"
      ) +
  scale_y_continuous(
    limits = c(0, 5)
  ) +
  # scale_y_continuous(
  #   breaks = seq(from = 0, to = 0.5, by = 0.05),
  #   limits = c(0, 0.5)#,
  #   #labels = function(breaks){paste0(breaks, " s")}
  #   ) +
  ylab("Time (s)") +
  xlab("Number of Features") +
  labs(
    title = "Dot Plot Performance",
    subtitle =
      "(200k Cells x 29k Genes, HDF5Array Compression Level 3 for SCE objects)"
  ) +
  guides(
    color =
      guide_legend(
        title = NULL
        )
  ) +
  theme_cowplot() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 18),
    plot.subtitle = element_text(hjust = 0.5),
    axis.text.x = element_text(size = 9)
    )

plot

ggsave(
  filename = "./plot_dot_vs_DotPlot_1-10_features.png",
  plot,
  device = "png",
  bg = "#FFFFFF"
)
```

# Perfromance Testing for plot_scatter (simple comparison)

```{r}
# Set up data collected from in silico performance test
time <- c()
test <- c()

# Trials per test
trials <- 25

cells_sobj <- get_all_cells(sobj)
cells_sce <- get_all_cells(sce_3)

cat("plot_scatter on Seurat object \n")
trial_name <- "plot_scatter, Seurat Object"

# Trial for n_features == i
results <- 
  repeat_trial(
    func = SCEPlots::plot_scatter, 
    n = trials,
    object = sobj,
    group_by = "ab200_clusters",
    feature_1 = "MEN1",
    feature_2 = "MEIS1"
    )

time <- c(time, results)
test <- c(test, rep_len(trial_name, trials))

cat("Seurat::FeatureScatter on Seurat object \n")
trial_name <- "FeatureScatter, Seurat Object"

# Trial for n_features == i
results <- 
  repeat_trial(
    func = Seurat::FeatureScatter, 
    n = trials,
    object = sobj,
    group.by = "ab200_clusters",
    feature1 = "MEN1",
    feature2 = "MEIS1"
    )

time <- c(time, results)
test <- c(test, rep_len(trial_name, trials))

cat("plot_scatter on SCE object \n")
trial_name <- "plot_scatter, SCE Object"

# Trial for n_features == i
results <- 
  repeat_trial(
    func = SCEPlots::plot_scatter, 
    n = trials,
    object = sce_3,
    group_by = "ab200_clusters",
    feature_1 = "MEN1",
    feature_2 = "MEIS1"
    )

time <- c(time, results)
test <- c(test, rep_len(trial_name, trials))

performance_results <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time
    )
  )

performance_results$Test <- 
  factor(
    performance_results$Test, 
    levels = 
      c("FeatureScatter, Seurat Object",
        "plot_scatter, Seurat Object",
        "plot_scatter, SCE Object"
        )
    )

plot <- 
  ggplot(data = performance_results, aes(x = Test, y = Time)) +
  geom_boxplot(aes(color = Test)) +
  scale_color_manual(
      values = 
        ggsci::pal_aaas("default")(10)[c(1,4,3)],
      aesthetics = "color",
      na.value = "grey50"
      ) + 
  scale_y_continuous(
    breaks = seq(from = 0, to = 5, by = 1),
    limits = c(0, 5)#,
    #labels = function(breaks){paste0(breaks, " s")}
    ) +
  ylab("Time (s)") +
  xlab("Function") +
  theme_cowplot() +
  theme(
    axis.text.x = element_text(size = 9)
    )

plot

ggsave(
  filename = "./Performance_plot_scatter_vs_FeatureScatter.png",
  plot,
  device = "png",
  bg = "#FFFFFF"
)
```

# Performance test: fetch_metadata with all variables, or pulling the full table 
```{r}
# Pulling full metadata table: Seurat object
full_table_seurat <- 
  function(object){
    object@meta.data
  }

# Pull full metadata table for SingleCellExperiment object
full_table_sce <- 
  function(object){
    colData(object)
  }

# Set up data collected from in silico performance test
time <- c()
test <- c()

# Trials per test
trials <- 25

allmeta_sobj <- SCEPlots::meta_varnames(sobj)
allmeta_sce <- SCEPlots::meta_varnames(sce_3)

cat("fetch_metadata on Seurat object \n")
trial_name <- "fetch_metadata, Seurat Object"

# Trial for n_features == i
results <- 
  repeat_trial(
    func = SCEPlots::fetch_metadata, 
    n = trials,
    object = sobj,
    vars = allmeta_sobj
    )

time <- c(time, results)
test <- c(test, rep_len(trial_name, trials))

cat("full_table on Seurat object \n")
trial_name <- "Fetch full table, Seurat Object"

# Trial for n_features == i
results <- 
  repeat_trial(
    func = full_table_seurat, 
    n = trials,
    object = sobj
    )

time <- c(time, results)
test <- c(test, rep_len(trial_name, trials))

cat("fetch_metadata on SCE object \n")
trial_name <- "fetch_metadata, SCE object"

# Trial for n_features == i
results <- 
  repeat_trial(
    func = SCEPlots::fetch_metadata, 
    n = trials,
    object = sce_3,
    vars = allmeta_sce
    )

time <- c(time, results)
test <- c(test, rep_len(trial_name, trials))

cat("full_table on Seurat object \n")
trial_name <- "Fetch full table, SCE Object"

# Trial for n_features == i
results <- 
  repeat_trial(
    func = full_table_sce, 
    n = trials,
    object = sce_3
    )

time <- c(time, results)
test <- c(test, rep_len(trial_name, trials))

performance_results <-
  data.frame(
    list(
    "Test" = test, 
    "Time" = time
    )
  )

performance_results$Test <- 
  factor(
    performance_results$Test, 
    levels = 
      c("fetch_metadata, Seurat Object",
        "Fetch full table, Seurat Object",
        "fetch_metadata, SCE object",
        "Fetch full table, SCE Object"
        )
    )

plot <- 
  ggplot(data = performance_results, aes(x = Test, y = Time)) +
  geom_boxplot(aes(color = Test)) +
  scale_color_manual(
      values = 
        ggsci::pal_aaas("default")(10)[c(1,4,5,3)],
      aesthetics = "color",
      na.value = "grey50"
      ) + 
  scale_y_continuous(
    #breaks = seq(from = 0, to = 1),
    limits = c(0, 0.75)#,
    #labels = function(breaks){paste0(breaks, " s")}
    ) +
  ylab("Time (s)") +
  xlab("Function") +
  theme_cowplot() +
  theme(
    axis.text.x = element_text(size = 9)
    )

plot

# ggsave(
#   filename = "./Performance_plot_scatter_vs_FeatureScatter.png",
#   plot,
#   device = "png",
#   bg = "#FFFFFF"
# )
```

# Monday, June 12th, 2023
Explore potential issue with plot_reduction with non-UMAP reductions

```{r}
plot_reduction(
  object = sce_3,
  group_by = "ab200_clusters",
  reduction = "TOTALVI_LNGB"
)

plot_reduction(
  object = sce_3,
  group_by = "ab200_clusters",
  reduction = "UMAP"
)
```


# Monday, August 21st, 2023
## Anndata exploration

Test AML object

```{python}
import anndata as ad
py_obj = ad.read_h5ad("./inst/extdata/AML_h5ad.h5ad")
import pandas as pd
import numpy as np

# Counts matrix
py_obj.X

type(py_obj.obs_names)

# Conditional for feature name present
features = py_obj.var_names
"FIS1" in features

# Attempt at subsetting (haven't figured out how to subset for all cells)
py_obj[[py_obj.obs_names], ["FIS1"]]

# Print column names of the metadata table
py_obj.obs.columns

# Print unique metadata values of a variable (condensed_cell_type)
np.unique(py_obj.obs["condensed_cell_type"])

# Subset for BM, PBMC monocytes
# Subset for a single cell type
py_obj[py_obj.obs.condensed_cell_type == "PBMC Monocytes"]

# Subset for both cell types: uses isin() method
py_obj[py_obj.obs.condensed_cell_type.isin(['BM Monocytes', 'PBMC Monocytes'])]

py_obj.layers
```

```{r}
object <- anndata::read_h5ad("./inst/extdata/AML_h5ad.h5ad")
object


```

### Construct new Anndata object from Austin

```{r}
reticulate::use_condaenv("anndata")
```


```{python}
import scanpy as sc
import numpy as np
import anndata as ad

# Construct UMAP using totalVI embedding from Austin
adata = sc.read_h5ad("./aml_ensemble_h5ad/aml_ensemble_combined_filtered.h5ad")
adata.obsm['X_totalVI'] = np.load("./aml_ensemble_h5ad/latent_rep_aml_ensembleV_ccmt.npy")
sc.pp.neighbors(adata, use_rep="X_totalVI")
sc.tl.umap(adata)

# Save new object to disk
adata.write("./aml_ensemble_h5ad/aml_ensemble_combined_filtered_umap.h5ad", compression = "gzip")
```

### Error when plotting on new object
```{r}
bigobj <- anndata::read_h5ad("./aml_ensemble_h5ad/aml_ensemble_combined_filtered_umap.h5ad")

# Running on "orig_ident" causes an error
SCEPlots::plot_reduction(bigobj, group_by = "orig_ident")

# Error comes from fetch_metadata
SCEPlots::fetch_metadata(bigobj, vars = "orig_ident")

# Manual inspection of "orig_ident" metadata
bigobj$obs$orig_ident |> head()
```

## Exploring mudata 

```{python}
# Load modules
import tempfile

import anndata as ad
import matplotlib.pyplot as plt
import mudata as md
import muon
import scanpy as sc
import scvi
import torch
```

```{python}
scvi.settings.seed = 0
print("Last run with scvi-tools version:", scvi.__version__)

# Additional setup
sc.set_figure_params(figsize=(4, 4))
torch.set_float32_matmul_precision("high")
save_dir = tempfile.TemporaryDirectory()

# Config magics do not work in reticulate
# %config InlineBackend.print_figure_kwargs={'facecolor' : "w"}
# %config InlineBackend.figure_format='retina'
# %config
```

```{python}
# PBMC 10K tutorial 
# Download data
adata = scvi.data.pbmcs_10x_cite_seq(save_path=save_dir.name)
adata
```

```{python}
# Normalize counts
# Create counts layer from X
adata.layers["counts"] = adata.X.copy()
# Normalize
sc.pp.normalize_total(adata)
sc.pp.log1p(adata)
# Add numerical suffix to duplicated feature names
adata.obs_names_make_unique()
```

```{python}
# Create separate anndata object from protein expression
protein_adata = ad.AnnData(adata.obsm["protein_expression"])
# Copy cell names to new object
protein_adata.obs_names = adata.obs_names
# delete protein expression data from the original object
del adata.obsm["protein_expression"]

# Create mudata object from the separate anndata objects
mdata = md.MuData({"rna": adata, "protein": protein_adata})
mdata
```

```{python}
# Compute highliy variable genes and place in a separate modality
sc.pp.highly_variable_genes(
    mdata.mod["rna"],
    n_top_genes = 4000,
    flavor = "seurat_v3",
    batch_key = "batch",
    layer = "counts",
    )

mdata.mod["rna_subset"] = mdata.mod["rna"][
    :, mdata.mod["rna"].var["highly_variable"]
].copy()

mdata.write("/Users/billshowers/1A_Jordan_Lab/Objects/test_mudata/mudata_PBMC10k.h5mu")
```

## Convert Ensemble anndata object to Mudata format
```{python}
import anndata as ad
import matplotlib.pyplot as plt
import mudata as md
import muon
import scanpy as sc
import scvi
import torch

# Read object
bigobj = ad.read("/Users/billshowers/1A_Jordan_Lab/Objects/aml_ensemble_h5ad/aml_ensemble_combined_filtered_umap.h5ad")

# Remove features from obs
bigobj.obs = bigobj.obs.iloc[:,0:25]

# Isolate protein data, delete from obsm
# An anndata object is being created from the protein data (more than just
# copying the matrix)
big_protein = ad.AnnData(bigobj.obsm["protein"])

# Copy observation names from the original object to the protein matrix
# (this may not be necessary)
big_protein.obs_names = bigobj.obs_names

del bigobj.obsm["protein"]

# Create MuData object
big_mdata = md.MuData({"rna": bigobj, "adt": big_protein})
#big_mdata

# Add "counts" layer
# big_mdata["adt"].layers["counts"] 

# Write Mudata object to file
big_mdata.write("/Users/billshowers/1A_Jordan_Lab/Objects/aml_ensemble_h5ad/aml_ensemble_combined_filtered_mudata")
```

# Anndata FetchData Draft

```{r}
library(reticulate)

obj <- anndata::read_h5ad("~/1A_Jordan_Lab/Objects/aml_ensemble_h5ad/aml_ensemble_combined_filtered_umap.h5ad")
cells <- NULL
slot <- NULL
vars <- 
  c("CDC20", 
    "JPT1", 
    "TACC3", 
    "PIMREG", 
    "protein_CD14", 
    "protein_CD45"#, 
    #"X_umap_1", 
    #"X_umap_2"
    )

#########

 # 1. Set default values
# Slot (assay): if null, data will be pulled from object$X

# Cells: if NULL, use all cells in the object
cells <- cells %||% get_all_cells(obj)

# 2. Identify which experiments/reductions have keyed features requested
# for them. Loop through experiments and reductions, instead of looping
# through each var

# Get a list of all "keys" in the object (this is restricted to obsm for now)
# The python method obsm_keys() is much faster than names(object$obsm)
key_names <-
  obj$obsm_keys()

# Construct a list of keys with the indices of vars that match each key
keyed_var_locations <-
  lapply(
    key_names,
    function(key){
      # grep returns the indices of matching vars
      grep(pattern = paste0('^', key), x = vars)
    }
  )

names(keyed_var_locations) <- key_names

# Subset list for keys that have at least one matching var
keyed_var_locations <-
  Filter(
    # Filter list for elements with any length
    f = length,
    x = keyed_var_locations
    )

# Anndata specific: if there are obsm variables specified, notify the user that
# the slot argument will be ignored for those features
if (length(keyed_var_locations) > 0){
  warning(
    '`slot` parameter is ignored any features entered that are not in "X".'
    )
}

# 3. Get data from each of the keyed locations with vars
py$fetched_data <-
      lapply(
        # Loops through locations of keyed variables, 
        # not the variables themselves
        names(keyed_var_locations),
        function(key){
          # Variables in current key location
          key_vars <- vars[keyed_var_locations[[key]]]

          # Remove experiment key for feature retrieval
          keyless_vars <-
            gsub(
              pattern = paste0('^', key, '_(.*)'),
              replacement = "\\1",
              x = key_vars,
              fixed = FALSE
            )

          # Retrieve data
          # (The below conditional is always TRUE for now, but may 
          # not be in the future)
          if (key %in% obj$obsm_keys()){
            # Fetch matrix at the location in obsm defined by the key
            py$matrix <- py_eval('obj.obsm[r.key]') # r_to_py(obj$obsm[[key]])
            
            # Create a pandas dataframe from the matrix if it is not one already
            if (!"pd.core.frame.DataFrame" %in% class(py$matrix)){
              #py_eval('import pandas as pd')
              py_eval(
                'pd.DataFrame(
                  matrix, 
                  index = r.obj.obs_names, 
                  columns = [r.key + "_" + str(x) for x in range(1, matrix.shape[1] + 1)]
                  )'
                )
            }
            
            # Subset to variables that are included in the current key location 
            # (to avoid slicing errors)
            keyless_vars <- keyless_vars[keyless_vars %in% colnames(py$matrix)]
            
            
            # Fetch data for the variables in the current location 
            # (but only if at least one variable is in the column names)
            if (length(keyless_vars) > 0){
              py$data <- py_eval('matrix.loc[r.cells, r.keyless_vars]')
              # R notation: does not evaluate properly
              #py$data <- py$matrix$loc[cells, keyless_vars]
            } else {
              # Return an empty dataframe if no variables are found
              py$data <- py_eval('pd.DataFrame()')
            }
            
            # Add experiment key back in 
            # Operation is written in python and evaluated via reticulate 
            # (this is required to modify a pandas dataframe)
            if (nrow(py$data) > 0){
              py$data <-
                py_eval(
                  'data.rename(lambda x: r.key + "_" + x, axis = "columns")'
                  )
              }
          }

          # Return pandas dataframe for the given location
          py$data
        }
      )

# Concatenate the list of DataFrames into a single DataFrame
py$fetched_data <- 
  py_eval(
    'pd.concat(
      fetched_data,
      axis = 1
      )'
    )

# 4. Fetch metadata variables
# Identify metadata variables


fetched_data
```

```{python}
# Renaming columns in a table
r.data_i.rename(lambda x: "protein_" + x, axis = "columns")

```

```{python}
# Create a data frame from a matrix
import pandas as pd

py_df = pd.DataFrame(
  matrix, 
  index = r.obj.obs_names, 
  columns = 
    [r.key + "_" + str(x) for x in range(1, matrix.shape[1] + 1)]
  )

pd.DataFrame(matrix, index = r.obj.obs_names, columns = [r.key + "_" + str(x) for x in range(1, matrix.shape[1] + 1)])

py_df.head()
```

```{r}
reduction <- "X_umap"

# Compare to R dataframe
ret <- 
  as.data.frame(
    obj$obsm[[reduction]], 
    row.names = obj$obs_names, 
    )

colnames(ret) = 
  paste(
    reduction, 
    1:dim(obj$obsm[[reduction]])[2], 
    sep = "_"
    )
```

```{python}
# Empty df
pd.DataFrame()
```

```{r}
```

```{python}
# Test of joining dataframes in python
import pandas as pd
import numpy as np

test_list = [
  pd.DataFrame(
    np.array(
      [[1, 2], [3, 4], [5, 6]]
      ), 
      index = ["A", "B", "C"], 
      columns = ["a", "b"]
      ),
  pd.DataFrame(
    np.array(
      [[7, 8], [9, 10], [11, 12]]
      ), 
    index = ["A", "B", "C"], 
    columns = ["c", "d"]
    )
    ]
    
test_list_with_empty = [
  pd.DataFrame(
    np.array(
      [[1, 2], [3, 4], [5, 6]]
      ), 
      index = ["A", "B", "C"], 
      columns = ["a", "b"]
      ),
  pd.DataFrame(
    np.array(
      [[7, 8], [9, 10], [11, 12]]
      ), 
    index = ["A", "B", "C"], 
    columns = ["c", "d"]
    ),
  pd.DataFrame()#,
  # pd.DataFrame(
  #   np.array(
  #     [[7, 8], [9, 10], [11, 12]]
  #     ), 
  #   index = ["A", "B", "C"], 
  #   columns = ["c", "d"]
  #   )
  ]

pd.concat(
  test_list_with_empty,
  axis = 1,
  verify_integrity = True
)

```

# Python Fetchdata

```{r}
# Load object, set up arguments for python function
object <- 
  anndata::read_h5ad(
    "~/1A_Jordan_Lab/Objects/aml_ensemble_h5ad/aml_ensemble_combined_filtered_umap.h5ad"
    )
cells <- NULL
slot <- NULL
# vars for tests (not in the ensembl object)
# vars <- 
#   c("CDC20", 
#     "JPT1", 
#     "TACC3", 
#     "PIMREG", 
#     "protein_CD14", 
#     "protein_CD45",
#     "Phase"#,
#     #"X_umap_1", 
#     #"X_umap_2"
#     )

set.seed(42)
gene_vars <- object$var_names[sample(1:length(object$var_names), size = 3)]

vars <-
  c(gene_vars,
    # Gene with the X_ key prepended
    # Note this is the same as one of the randomly generated variables above
    # (CATSPER4). This should be compared to how Seurat handles data
    "X_CATSPER4",
    # Duplicate entry (must not be added to dataframe)
    "X_CATSPER4",
    # ADT variables
    "protein_CD14",
    "protein_CD45",
    # Protein vars without the key specified
    "CD36",
    # Metadata
    "Phase",
    # Keyed metadata
    "obs_sample_name",
    # Reductions (causes problems)
    "X_umap_1",
    "X_umap_2",
    # Nonsensical variable (should have no location)
    "1"
    )
```


```{python}
# Load libraries
import pandas as pd
import numpy as np
from scipy.sparse import csr_matrix
# import anndata as adata
from collections import Counter

import re
```


```{python}
# Functions used
def is_match(regex_search, target):
    """
    Returns True if a regex is found in a target string, and 
    False if not.
    
    Arguments
    ----------
    regex_string: a regex expression to search for, formatted 
    as a string.
    
    target (string): the target for which to search regex_string.
    """
    regex = re.compile(regex_search)
    
    if regex.search(target):
        return True
    else: 
        return False

def fetch_keyed_vars(obj, target_vars):
    """
    Returns expression data for all variables in target_vars that are
    found in the object at obj. Expression data will be returned only 
    for the variables that have an location key associated with them
    (i.e. X_FIS1 for a gene, obs_sample_id for a metadata variable, or
    (obsm_key)_var for a variable in an obsm matrix).
    
    Arguments
    ----------
    obj: an anndata object.
    
    target_vars: a set of variables to search the object for. Variables
    without a location key may be entered, but data will not be returned
    for these variables.
    
    Return
    ----------
    A pandas DataFrame with expression data for each of the requested 
    variables in target_vars.
    """
    # Dataframe will store expression data for all variables found
    data_return = pd.DataFrame()
    
    # Get a list of all "keys" in the object 
    # Currently supported locations: X, obs, and matrices within obsm
    key_names = ["X", "obs"] + list(obj.obsm_keys())
    
    # Construct a list of keys with the indices of vars that match each key
    keyed_var_locations = []
  
    for key in key_names:
        ## 2.1. Search for keyed vars for the current location in target_vars ####
        # Create regex object from the current key for searching
        # Capture group will return the text in the var after the key and "_" 
        # (the name of the var in the matrix)
        key_regex = re.compile("^" + key + "_(.*)")
        
        # matches: a dictionary mapping the original keyed var to the "keyless" 
        # var produced from removing the key plus an underscore. The keyless var 
        # is how the var should appear in the matrix it is being pulled from.
        
        # Dictionary comprehension is used to return variables for which the 
        # regex search is "truthy". When a match is found, a a regex match 
        # object will be returned, which will evaluate as true in the if 
        # statement below.
        matches = {var:key_regex.search(var).groups()[0] 
            for var in target_vars 
            if key_regex.search(var)
            }
        
        # For the X matrix, the user may use a key that conflicts with the names 
        # of common obsm matrices, such as "X_umap". To prevent "X_umap_1" from 
        # causing the function to search the gene matrix for "umap_1", keyless 
        # vars that contain an object key before an underscore will be removed.
        
        # NOTE: if there happens to be a gene that contains an obsm matrix name 
        # plus an underscore, this gene will be unsearchable due to this 
        # workaround. This does not seem likely however, as there are no known 
        # human genes with underscores or reduction names in the gene symbol.
        if key == "X":
            # Define other keys in object 
            exclusion_keys = [key for key in key_names if key != "X"]
            
            # Return regex matches...
            matches = {key:value for (key, value) in matches.items() 
                # ... where none of the other keys in the object are found in 
                # the original var entry (before the key is removed)
                if not any([is_match(regex_search = exclusion_key, target = key) 
                    for exclusion_key in exclusion_keys])
                }
            
        # Extract values from curated matches dictionary (keyless vars to search 
        # X/obs/obsm matrix for)
        keyless_vars = list(matches.values())
        
        ## 2.2. Fetch Data if vars exist in the current location ####
        if (len(keyless_vars) > 0):
            
            ### 2.2.1. Pull expression matrix for the current key location ####
            if key == "X":
                # The X matrix alone supports "slot" (via layers)
                # TODO: pull from layers when slot != None
                matrix = obj.X
            elif key == "obs":
                # Metadata (obs)
                matrix = obj.obs
            elif key in obj.obsm_keys():
                # For a key in the list of obsm keys, pull matrix for that entry
                matrix = obj.obsm[key]
                    
            ### 2.2.2. Pull data for cells, keyless vars from matrix ####
            # Type checking via isinstance is used here due to the variety of
            # data types possible for the matrix
            # This is not considered "pythonic" and may need to be re-thought 
            # https://stackoverflow.com/questions/2225038/determine-the-type-of-an-object
            if (isinstance(matrix, csr_matrix)):
                # Sparse matrix format (X): subset *object for genes, then 
                # construct a pandas dataframe (sparse matrices don't subset 
                # easily in python)
                data = pd.DataFrame.sparse.from_spmatrix(
                    obj[:, keyless_vars].X,
                    # csr_matrices don't have row, column names. 
                    # These are added here
                    index = obj.obs_names,
                    columns = keyless_vars
                    )
            elif (isinstance(matrix, pd.DataFrame)):
                # Pandas dataframe: pull data via .loc 
                data = matrix.loc[cells, keyless_vars]
            elif (isinstance(matrix, np.ndarray)):
                # Numpy arrays
                
                # The process below was designed with the assumption that only 
                # reductions would have this format. It should be applicable 
                # to other arrays however since arrays are stored without column
                # names, and the user would likely reference variables in these
                # arrays using an index (i.e. "X_umap_1", "(matrix_name)_1")
                
                # Convert numpy array to pandas datafrane, then slice for vars
                matrix = pd.DataFrame(
                    matrix,
                    index = obj.obs_names,
                    # Construct var names using a 1-based index (for consistency 
                    # with Seurat, R objects used in SCUBA)
                    columns = [str(x) for x in range(1, matrix.shape[1] + 1)]
                    )
                    
                # Slice based on keyless vars (should be string format of the 
                # column desired, "1" for the first column)
                data = matrix.loc[cells, keyless_vars]
                
            else:
                """
                Strings wrapped according to PEP-8 style guidelines
                https://stackoverflow.com/questions/1874592/
                how-to-write-very-long-string-that-conforms-with-
                pep8-and-prevent-e501
                """
                raise NotImplementedError(
                    ("FetchData does not know how to handle a matrix of class {0}. "
                    "This ocurred with the matrix at key '{1}'."
                    ).format(type(matrix), key)
                    )
            
            # Add location key back in to variable names (if ncol is greater than 
            # zero)
            if data.shape[1] > 0:
                # Lambda function prepends the key and "_" to each element
                data = data.rename(lambda x: key + "_" + x, axis = "columns")
                
            # Concatenate data frame with data already fetched
            data_return = pd.concat(
                [data_return, data],
                axis = 1
                )
            
    # When finished with iteration, return the dataframe
    return data_return

def fetch_anndata(obj, fetch_vars, cells=None, slot=None):
    """
    Fetches the specified variables from an anndata object.
    
    Arguments
    ----------
    obj: an anndata object.
    
    fetch_vars: a list giving the variables to fetch from the object.
    Variables entered should ideally have a key prepended with the 
    location of the variable in the object, for example, to pull the
    FIS1 gene from the genes matrix (X), specify "X_FIS1" instead of
    "FIS1". To pull metadata, use "obs_", and to pull data from a 
    matrix in obsm, use the name of that matrix, not obsm. For 
    example, if a matrix in obsm is named "protein", use "protein_" 
    to pull data from that matrix. Variables that are entered without
    a key can still be found, as long as there is only one matrix in 
    the object with that variable name. Variables that do not have a 
    valid key (X_, obs_, and a key from obj.obsm_names()) will be 
    ignored, as will duplicate variables.
    
    cells: Optional, a list of cells to return data for. If left as 
    None, data will be returned for all cells in the object.
    
    slot: Optional, a string specifying the layer to return data from, 
    provided the variable in question is from the X matrix. The slot
    argument is ignored for variables from all other locations.
    """
    # 1. Set default values
    # Slot (assay): if null, data will be pulled from object$X

    # Cells: if None (NULL), use all cells in the object
    if cells == None:
        cells = list(obj.obs_names)
    
    # 2. Check fetch_vars for duplicate entries
    
    # "fetch_vars" is used instead of "vars" since vars is a base 
    # python function
    
    # Use collections.Counter to find duplicates
    # Must iterate through the keys of the dictionary produced by counter
    # If iterating through fetch_vars, duplicates will display twice (or as
    # many times as they appear in fetch_vars)
    duplicate_vars = [var
        for var in Counter(fetch_vars).keys()
        if Counter(fetch_vars)[var] > 1
        ]
    
    # Report duplicates to the user and notify that only one entry 
    # will be included 
    warnings.warn(
      ("Duplicate entries passed to vars: " +
      ", ".join(duplicate_vars) +
      ". Only one entry for each variable will be returned.")
      )

    # Remove duplicates by converting fetch_vars to a set, 
    # and then back to a list
    fetch_vars = list(set(fetch_vars))
    
    # 3. Pull data for keyed features in each key location
    # (uses fetch_keyed_vars function)
    fetched_data = fetch_keyed_vars(
        obj = obj, 
        target_vars = fetch_vars
        )
    
    # 4. Identify location of remaining vars
    # Feature data can appear in object.obs (metadata), so ambiguous vars 
    # should be checked to avoid returning incorrect data in the case of data 
    # being found in multiple assays
    
    # Identify remaining variables via list comprehension
    remaining_vars = [
        var_i 
        for var_i in fetch_vars 
        if var_i not in list(fetched_data.columns)
        ]
    
    # Determine the location of each remaining variable
    remaining_locations = {}
    
    # Names of variables in X are likely very large, so the variables that 
    # are members of X should be determined first
    X_vars = [
        remaining_var 
        for remaining_var in remaining_vars 
        if remaining_var in obj.var_names
        ]
    
    # Do the same for metadata
    metadata_vars = [
        remaining_var
        for remaining_var in remaining_vars 
        if remaining_var in obj.obs_keys()
        ]
    
    for remaining_var in remaining_vars:
        # For each variable, create a dictionary entry with an empty list
        # Append locations to the list for each variable when it is found
        remaining_locations[remaining_var] = []
        
        # Check X vars computed above
        if remaining_var in X_vars:
            remaining_locations[remaining_var].append("X")
        
        # Check metadata vars
        if remaining_var in metadata_vars:
            remaining_locations[remaining_var].append("obs")
        
        # Look in obsm locations
        for obsm_key in obj.obsm_keys():
            # Must test pandas DataFrames separately to avoid 
            # errors with .columns 
            if isinstance(obj.obsm[obsm_key], pd.DataFrame):
                # Look for var in the columns of the dataframe 
                if remaining_var in obj.obsm[obsm_key].columns:
                    remaining_locations[remaining_var].append(obsm_key)
            else:
                # Ignore matrices that are not pandas dataframes for now
                # (reductions should not make it to this step since a key is 
                # required to distinguish reduction dimensions (X_umap_1 vs. 
                # X_tsne_1), "1" would not be specific enough). Matrices with 
                # searchable variable names should not be numpy arrays
                pass
    
    # 5. Warn the user if remaining vars are found in multiple locations
    # Need a warning that does not interrupt the function (warnings behave 
    # like errors when called with raise)
    
    # Identify remaining vars in multiple locations
    ambiguous_vars = {key:value 
                          for (key, value) in remaining_locations.items() 
                          if len(value) > 1
                          }
                        
    if len(ambiguous_vars) > 0:
        # Display an example of how to remove ambiguous vars to the user
        # Store an ambiguous var, and the possible keys that can be added
        example_var = list(ambiguous_vars.keys())[0]
        example_keys = ambiguous_vars[example_var]
        
        # Generate a list of the features to be en
        example_entries = [key + "_" + example_var for key in example_keys]
        
        # Construct string from examples
        if len(example_entries) == 2:
            # If there are two possible entries, add "or" between the examples 
            example_str = ", or ".join(example_entries)
        elif len(example_entries) > 2:
            # If there are more than two possibilities, add "or" before the 
            # last entry and join all other entries with a comma.
            example_entries[-1] = "or " + example_entries[-1]
            example_str = ", ".join(example_entries)
        
        # Display warning message
        warnings.warn(
            ("The following variables were found in multiple assays: " +
            ", ".join(list(ambiguous_vars.keys())) +
            ". These variables will not be retrieved due to ambiguity. " +
            "To pull data for these variables, please specify which " +
            "location in the object to pull the variable from using an " + 
            "underscore (for example: " +
            example_str +
            ")."
            )
            )
            
    # 6. Fetch data for remaining vars ####
    # Keys will be added, and then data will be fetched for the new keyed vars
    
    ## 6.1. Add keys (for remaining vars where a key was identified) ####
    # Identify vars to add key to (vars with exactly one location identified)
    vars_add_key = {key:value 
        for (key, value) in remaining_locations.items() 
        if len(value) == 1
        }
    
    # Create dictionary mapping the vars above to their keyed equivalents
    # Add key with underscore to var name 
    map_keyed_vars = {key:value[0] + "_" + key 
        for (key, value) in vars_add_key.items()}
    
    
    new_keyed_vars = list(map_keyed_vars.values())

    ## 6.2. Catch duplicate vars ####
    # Vars without keys may be the same as those entered with keys. For 
    # example, FIS1 and X_FIS1 should describe the same variable. If 
    # duplicates are added to the fetch_data dataframe, unexpected behavior
    # will occur later on when the variables are sorted, and duplicate entries
    # of the same variable do not add any value to the user. If variables 
    # with keys added are the same as the keyed variables already fetched, the 
    # variable should not be added again. 
    
    # Construct a dictionary with variables that match existing columns in 
    # fetched_data after the key is added
    duplicate_vars = {
        var_entered:keyed_var 
        for (var_entered, keyed_var) in map_keyed_vars.items() 
        if keyed_var in fetched_data.columns
        }

    # Warn the user that a variable is duplicated and only one 
    # copy will be returned
    # For each key:value pair in duplicate vars, create a set of 
    # human-readable strings describing the feature entered and its 
    # equivalent duplicate
    duplicate_description = [key + ", equivalent to " + value 
        for (key, value) in duplicate_vars.items()]
    duplicate_description = "; ".join(duplicate_description)
    
    # Example of the keyed variable(s) to be returned
    will_be_returned = ", ".join(list(duplicate_vars.values()))
    
    warnings.warn(
        ("The following variables entered describe the same variable: " +
        duplicate_description + 
        ". Only the copy of the variable with the key entered will be " +
        "returned (" +
        will_be_returned +
        ").")
        )
    
    # Remove the duplicate variable(s) before fetching data
    new_keyed_vars = [var 
        for var in new_keyed_vars 
        if var not in duplicate_vars.values()]
        
    # Also remove duplicates from fetch_vars (this variable is used later on 
    # to sort the final dataframe, and duplicate entries in fetch_vars will
    # cause duplication in the dataframe).
    fetch_vars = [var 
        for var in fetch_vars
        if var not in duplicate_vars.values()]

    ## 6.3. Fetch data for new keyed variables and append to fetched_data ####
    new_data = fetch_keyed_vars(
        obj = obj, 
        target_vars = new_keyed_vars
        )
        
    fetched_data = pd.concat(
        [fetched_data, new_data],
        axis = 1
        )

    # 7. Determine which vars, if any, were not returned
    vars_not_found = [var for var in fetch_vars if var not in fetched_data.columns]
    
    # Record the vars found in 6 (these will show up in vars_not_found incorrectly
    # since the vars in fetch_data contain the new key added)
    new_keyed_vars_found = [var 
        for var in map_keyed_vars.keys() 
        if map_keyed_vars[var] in fetched_data.columns
        ]
        
    # Remove any vars in new_keyed_vars_found from vars_not_found
    vars_not_found = [var 
        for var in vars_not_found 
        if var not in new_keyed_vars_found
        ]
    
    # 8. Warnings/errors for variables not found ####
    # ten_plus_message: added to message if there are more than 10 
    # missing variables
    if (len(vars_not_found) > 10):
        ten_plus_message = "(10 out of {} shown)".format(len(vars_not_found))
    else:
        ten_plus_message = ""
    
    # Show an error if all vars were not found, and a warning if at least 
    # one var was not found
    if len(vars_not_found) == len(fetch_vars):
        raise ValueError(
            "None of the requested variables were found " +
            ten_plus_message +
            ": " +
            ", ".join(vars_not_found)
            )
    elif len(vars_not_found) > 0:
        warnings.warn(
            "The following requested variables were not found " +
            ten_plus_message +
            ": " +
            ", ".join(vars_not_found)
            )

    # 9. Sort columns, return fetched data ####
    # Order of columns in data should reflect the order entered, not the 
    # order fetched
    # Columns in dataframe use keys for all vars, including those entered 
    # without a key. To sort properly, keys are added to var names using 
    # the mapping produced in 6.
    # Get method: if a mapped keyed variable exists for var, that variable is 
    # returned. If not, the var is returned as-is.
    var_order = [map_keyed_vars.get(var, var) for var in fetch_vars]
    # Remove variables that are not in the column names of the dataframe
    # to avoid errors
    var_order = [var for var in var_order if var in fetched_data.columns]
    
    # Pass list to fetched_data to order columns accordingly
    fetched_data = fetched_data[var_order]

    return fetched_data
```

```{python}
# Call fetch_anndata function
fetch_anndata(
    fetch_vars = r.vars,
    obj = r.object,
    cells = r.cells,
    slot = r.slot
    )
```

```{python}
# Function arguments (these will be entered directly in the future)
# Must call object obj ("object" is a python keyword)
obj = r.object
cells = r.cells
slot = r.slot
# "vars" is a base Python function that should not be overwritten
fetch_vars = r.vars

# 1. Set default values
# Slot (assay): if null, data will be pulled from object$X

# Cells: if None (NULL), use all cells in the object
if cells == None:
    cells = list(obj.obs_names)

# 2. Check fetch_vars for duplicate entries
# Use collections.Counter to find duplicates
# Must iterate through the keys of the dictionary produced by counter
# If iterating through fetch_vars, duplicates will display twice (or as
# many times as they appear in fetch_vars)
duplicate_vars = [var
    for var in Counter(fetch_vars).keys()
    if Counter(fetch_vars)[var] > 1
    ]
    
# Report duplicates to the user and notify that only one entry 
# will be included 
warnings.warn(
  ("Duplicate entries passed to vars: " +
  ", ".join(duplicate_vars) +
  ". Only one entry for each variable will be returned.")
  )

# Remove duplicates by converting fetch_vars to a set, 
# and then back to a list
fetch_vars = list(set(fetch_vars))

# 3. Pull data for keyed features in each key location
# (uses fetch_keyed_vars function)
fetched_data = fetch_keyed_vars(
    obj = obj, 
    target_vars = fetch_vars
    )

# # Data for each var will be concatenated with the below DataFrame
# fetched_data = pd.DataFrame()
# 
# # Get a list of all "keys" in the object 
# # Currently supported locations: X, obs, and matrices within obsm
# key_names = ["X", "obs"] + list(obj.obsm_keys())
# 
# # Construct a list of keys with the indices of vars that match each key
# keyed_var_locations = []
# 
# for key in key_names:
#     ## 3.1. Search for keyed vars for the current location in fetch_vars ####
#     # Create regex object from the current key for searching
#     # Capture group will return the text in the var after the key and "_" (the 
#     # name of the var in the matrix)
#     key_regex = re.compile("^" + key + "_(.*)")
#     
#     # matches: a dictionary mapping the original keyed var to the "keyless" var
#     # produced from removing the key plus an underscore. The keyless var is how
#     # the var should appear in the matrix it is being pulled from.
#     
#     # Dictionary comprehension is used to return variables for which the regex
#     # search is "truthy". When a match is found, a a regex match object will be
#     # returned, which will evaluate as true in the if statement below.
#     matches = {var:key_regex.search(var).groups()[0] 
#         for var in fetch_vars 
#         if key_regex.search(var)
#         }
#     
#     # For the X matrix, the user may use a key that conflicts with the names of 
#     # common obsm matrices, such as "X_umap". To prevent "X_umap_1" from 
#     # causing the function to search the gene matrix for "umap_1", keyless vars
#     # that contain an object key before an underscore will be removed.
#     
#     # NOTE: if there happens to be a gene that contains an obsm matrix name 
#     # plus an underscore, this gene will be unsearchable due to this 
#     # workaround. This does not seem likely however, as there are no known 
#     # human genes with underscores or reduction names in the gene symbol.
#     if key == "X":
#         # Define other keys in object 
#         exclusion_keys = [key for key in key_names if key != "X"]
#         
#         # Return regex matches...
#         matches = {key:value for (key, value) in matches.items() 
#             # ... where none of the other keys in the object are found in the 
#             # original var entry (before the key is removed)
#             if not any([is_match(regex_search = exclusion_key, target = key) 
#                 for exclusion_key in exclusion_keys])
#             }
#             
#     # Extract values from curated matches dictionary (keyless vars to search 
#     # X/obs/obsm matrix for)
#     keyless_vars = list(matches.values())
#     
#     ## 3.2. Fetch Data if vars exist in the current location ####
#     if (len(keyless_vars) > 0):
#         
#         ### 3.2.1. Pull expression matrix for the current key location ####
#         if key == "X":
#             # The X matrix alone supports "slot" (via layers)
#             # TODO: pull from layers when slot != None
#             matrix = obj.X
#         elif key == "obs":
#             # Metadata (obs)
#             matrix = obj.obs
#         elif key in obj.obsm_keys():
#             # For a key in the list of obsm keys, pull matrix for that entry
#             matrix = obj.obsm[key]
#                 
#         ### 3.2.2. Pull data for cells, keyless vars from matrix ####
#         # Type checking via isinstance is used here due to the variety of data 
#         # types possible for the matrix
#         # This is not considered "pythonic" and may need to be re-thought 
#         # https://stackoverflow.com/questions/2225038/determine-the-type-of-an-object
#         if (isinstance(matrix, csr_matrix)):
#             # Sparse matrix format (X): subset *object for genes, then 
#             # construct a pandas dataframe (sparse matrices don't subset easily
#             # in python)
#             data = pd.DataFrame.sparse.from_spmatrix(
#                 obj[:, keyless_vars].X,
#                 # csr_matrices don't have row, column names. These are added here
#                 index = obj.obs_names,
#                 columns = keyless_vars
#                 )
#         elif (isinstance(matrix, pd.DataFrame)):
#             # Pandas dataframe: pull data via .loc 
#             data = matrix.loc[cells, keyless_vars]
#         elif (isinstance(matrix, np.ndarray)):
#             # Numpy arrays
#             
#             # The process below was designed with the assumption that only 
#             # reductions would have this format. It should be applicable 
#             # to other arrays however since arrays are stored without column
#             # names, and the user would likely reference variables in these
#             # arrays using an index (i.e. "X_umap_1", "(matrix_name)_1")
#             
#             # Convert numpy array to pandas datafrane, then slice for vars
#             matrix = pd.DataFrame(
#                 matrix,
#                 index = obj.obs_names,
#                 # Construct var names using a 1-based index (for consistency 
#                 # with Seurat, R objects used in SCUBA)
#                 columns = [str(x) for x in range(1, matrix.shape[1] + 1)]
#                 )
#                 
#             # Slice based on keyless vars (should be string format of the 
#             # column desired, "1" for the first column)
#             data = matrix.loc[cells, keyless_vars]
#             
#         else:
#             """
#             Strings wrapped according to PEP-8 style guidelines
#             https://stackoverflow.com/questions/1874592/
#             how-to-write-very-long-string-that-conforms-with-
#             pep8-and-prevent-e501
#             """
#             raise NotImplementedError(
#                 ("FetchData does not know how to handle a matrix of class {0}. "
#                 "This ocurred with the matrix at key '{1}'."
#                 ).format(type(matrix), key)
#                 )
#         
#         # Add location key back in to variable names (if ncol is greater than 
#         # zero)
#         if data.shape[1] > 0:
#             # Lambda function prepends the key and "_" to each element
#             data = data.rename(lambda x: key + "_" + x, axis = "columns")
#             
#         # Concatenate data frame with data already fetched
#         fetched_data = pd.concat(
#             [fetched_data, data],
#             axis = 1
#             )
```

```{python}
# 4. Identify location of remaining vars
# Feature data can appear in object.obs (metadata), so ambiguous vars should be
# checked to avoid returning incorrect data in the case of data being found in
# multiple assays

# Identify remaining variables via list comprehension
remaining_vars = [
    var_i 
    for var_i in fetch_vars 
    if var_i not in list(fetched_data.columns)
    ]

# Determine the location of each remaining variable
remaining_locations = {}

# Names of variables in X are likely very large, so the variables that are 
# members of X should be determined first
X_vars = [
    remaining_var 
    for remaining_var in remaining_vars 
    if remaining_var in obj.var_names
    ]

# Do the same for metadata (it is more efficient to examine the matrix one
# if this is possible)  
metadata_vars = [
    remaining_var
    for remaining_var in remaining_vars 
    if remaining_var in obj.obs_keys()
    ]

for remaining_var in remaining_vars:
    # For each variable, create a dictionary entry with an empty list
    # Append locations to the list for each variable when it is found
    remaining_locations[remaining_var] = []
    
    # Check X vars computed above
    if remaining_var in X_vars:
        remaining_locations[remaining_var].append("X")
    
    # Check metadata vars
    if remaining_var in metadata_vars:
        remaining_locations[remaining_var].append("obs")
    
    # Look in obsm locations
    for obsm_key in obj.obsm_keys():
        # Must test pandas DataFrames separately to avoid errors with .columns 
        if isinstance(obj.obsm[obsm_key], pd.DataFrame):
            # Look for var in the columns of the dataframe 
            if remaining_var in obj.obsm[obsm_key].columns:
                remaining_locations[remaining_var].append(obsm_key)
        else:
            # Ignore matrices that are not pandas dataframes for now
            # (reductions should not make it to this step since a key is 
            # required to distinguish reduction dimensions (X_umap_1 vs. 
            # X_tsne_1), "1" would not be specific enough). Matrices with 
            # searchable variable names should not be numpy arrays
            pass
```

```{python}
# 5. Warn the user if remaining vars are found in multiple locations
# Need a warning that does not interrupt the function (warnings behave like 
# errors when called with raise)

# Identify remaining vars in multiple locations
ambiguous_vars = {key:value 
                      for (key, value) in remaining_locations.items() 
                      if len(value) > 1
                      }
                    
if len(ambiguous_vars) > 0:
    # Display an example of how to remove ambiguous vars to the user
    # Store an ambiguous var, and the possible keys that can be added
    example_var = list(ambiguous_vars.keys())[0]
    example_keys = ambiguous_vars[example_var]
    
    # Generate a list of the features to be en
    example_entries = [key + "_" + example_var for key in example_keys]
    
    # Construct string from examples
    if len(example_entries) == 2:
        # If there are two possible entries, add "or" between the examples 
        example_str = ", or ".join(example_entries)
    elif len(example_entries) > 2:
        # If there are more than two possibilities, add "or" before the last
        # entry and join all other entries with a comma.
        example_entries[-1] = "or " + example_entries[-1]
        example_str = ", ".join(example_entries)
    
    # Display warning message
    warnings.warn(
        ("The following variables were found in multiple assays: " +
        ", ".join(list(ambiguous_vars.keys())) +
        ". These variables will not be retrieved due to ambiguity. " +
        "To pull data for these variables, please specify which " +
        "location in the object to pull the variable from using an " + 
        "underscore (for example: " +
        example_str +
        ")."
        )
        )
```

```{python}
# 6. Fetch data for remaining vars ####
# Keys will be added, and then data will be fetched for the new keyed vars

## 6.1. Add keys (for remaining vars where a key was identified) ####
# Identify vars to add key to (vars with exactly one location identified)
vars_add_key = {key:value 
    for (key, value) in remaining_locations.items() 
    if len(value) == 1
    }

# Create dictionary mapping the vars above to their keyed equivalents
# Add key with underscore to var name 
map_keyed_vars = {key:value[0] + "_" + key 
    for (key, value) in vars_add_key.items()}


new_keyed_vars = list(map_keyed_vars.values())

## 6.2. Catch duplicate vars ####
# Vars without keys may be the same as those entered with keys. For 
# example, FIS1 and X_FIS1 should describe the same variable. If 
# duplicates are added to the fetch_data dataframe, unexpected behavior
# will occur later on when the variables are sorted, and duplicate entries
# of the same variable do not add any value to the user. If variables 
# with keys added are the same as the keyed variables already fetched, the 
# variable should not be added again. 

# Construct a dictionary with variables that match existing columns in 
# fetched_data after the key is added
duplicate_vars = {
    var_entered:keyed_var 
    for (var_entered, keyed_var) in map_keyed_vars.items() 
    if keyed_var in fetched_data.columns
    }

# Warn the user that a variable is duplicated and only one 
# copy will be returned
# For each key:value pair in duplicate vars, create a set of 
# human-readable strings describing the feature entered and its 
# equivalent duplicate
duplicate_description = [key + ", equivalent to " + value 
    for (key, value) in duplicate_vars.items()]
duplicate_description = "; ".join(duplicate_description)

# Example of the keyed variable(s) to be returned
will_be_returned = ", ".join(list(duplicate_vars.values()))

warnings.warn(
    ("The following variables entered describe the same variable: " +
    duplicate_description + 
    ". Only the copy of the variable with the key entered will be " +
    "returned (" +
    will_be_returned +
    ").")
    )
    
# Remove the duplicate variable(s) before fetching data
new_keyed_vars = [var 
    for var in new_keyed_vars 
    if var not in duplicate_vars.values()]
    
# Also remove duplicates from fetch_vars (this variable is used later on 
# to sort the final dataframe, and duplicate entries in fetch_vars will
# cause duplication in the dataframe).
fetch_vars = [var 
    for var in fetch_vars
    if var not in duplicate_vars.values()]

## 6.3. Fetch data for new keyed variables and append to fetched_data ####
new_data = fetch_keyed_vars(
    obj = obj, 
    target_vars = new_keyed_vars
    )
    
fetched_data = pd.concat(
    [fetched_data, new_data],
    axis = 1
    )

# 7. Determine which vars, if any, were not returned
vars_not_found = [var for var in fetch_vars if var not in fetched_data.columns]

# Record the vars found in 6 (these will show up in vars_not_found incorrectly
# since the vars in fetch_data contain the new key added)
new_keyed_vars_found = [var 
    for var in map_keyed_vars.keys() 
    if map_keyed_vars[var] in fetched_data.columns
    ]
    
# Remove any vars in new_keyed_vars_found from vars_not_found
vars_not_found = [var 
    for var in vars_not_found 
    if var not in new_keyed_vars_found
    ]
    
# 8. Warnings/errors for variables not found ####
# ten_plus_message: added to message if there are more than 10 
# missing variables
if (len(vars_not_found) > 10):
    ten_plus_message = "(10 out of {} shown)".format(len(vars_not_found))
else:
    ten_plus_message = ""

# Show an error if all vars were not found, and a warning if at least 
# one var was not found
if len(vars_not_found) == len(fetch_vars):
    raise ValueError(
        "None of the requested variables were found " +
        ten_plus_message +
        ": " +
        ", ".join(vars_not_found)
        )
elif len(vars_not_found) > 0:
    warnings.warn(
        "The following requested variables were not found " +
        ten_plus_message +
        ": " +
        ", ".join(vars_not_found)
        )

# 9. Return fetched data ####
# Order of columns in data should reflect the order entered, not the 
# order fetched
# Columns in dataframe use keys for all vars, including those entered 
# without a key. To sort properly, keys are added to var names using 
# the mapping produced in 6.
# Get method: if a mapped keyed variable exists for var, that variable is 
# returned. If not, the var is returned as-is.
var_order = [map_keyed_vars.get(var, var) for var in fetch_vars]
# Remove variables that are not in the column names of the dataframe
# to avoid errors
var_order = [var for var in var_order if var in fetched_data.columns]

# Pass list to fetched_data to order columns accordingly
fetched_data = fetched_data[var_order]

# Return fetched_data
#return fetched_data
fetched_data
```

# Test sourcing of python Fetch_Data function

All environments were cleared prior to running the test.

```{r}
source_python("./inst/extdata/Python/fetch_anndata.py")

object <- 
  anndata::read_h5ad(
    "~/1A_Jordan_Lab/Objects/aml_ensemble_h5ad/aml_ensemble_combined_filtered_umap.h5ad"
    )

set.seed(42)
gene_vars <- object$var_names[sample(1:length(object$var_names), size = 3)]

vars <-
  c(gene_vars,
    # Gene with the X_ key prepended
    # Note this is the same as one of the randomly generated variables above
    # (CATSPER4). This should be compared to how Seurat handles data
    "X_CATSPER4",
    # Duplicate entry (must not be added to dataframe)
    "X_CATSPER4",
    # ADT variables
    "protein_CD14",
    "protein_CD45",
    # Protein vars without the key specified
    "CD36",
    # Metadata
    "Phase",
    # Keyed metadata
    "obs_sample_name",
    # Reductions (causes problems)
    "X_umap_1",
    "X_umap_2",
    # Nonsensical variable (should have no location)
    "1"
    )

py$data <- py$fetch_anndata(
  obj = object,
  fetch_vars = vars,
  cells = NULL,
  slot = NULL
  )

class(py$data)
```

```{r}
plot_feature(
  object = object,
  features = "X_CATSPER4"
)
```

```{python}
fetch_anndata(
  obj = r.object,
  fetch_vars = list(r.vars),
  cells = None,
  slot = None
  )
```

# Address Issues with Table Return from Reticulate 
Thursday, September 21st, 2023

The table returned by fetch_anndata is a Pandas dataframe with numpy arrays for columns. Reticulate converts the dataframe as a whole to an R `data.frame` when the table is accessed in R, but the columns remain as numpy arrays, making downstream operation in R impossible. Solutions to this are explored below.

```{r}
# py$data: output of fetch_anndata
# Explicit conversion to R data.frame
r_frame <- 
    data.frame(py$data)
# This did not work
```

```{python}
# Conversion of python object to a csr_matrix
from scipy.sparse import csr_matrix, csr_array

csr_array(data)
```

## Inconsistencies in pd.loc behavior in Reticulate

```{r}
# Extract a pandas dataframe from the object
py$matrix = object$obsm$protein

# Define column names to fetch
var_subset <- c("CD14", "CD45")

var_subset %in% colnames(py$matrix)

# Define rows (cells) to fetch
cells = SCEPlots::get_all_cells(object)

all(cells %in% rownames(py$matrix))

# Fetch data using pd.loc
py$matrix$loc[cells, var_subset]
```

```{python}
# Same operation in python
matrix.loc[r.cells, r.var_subset]

matrix.loc(r.cells, r.var_subset)
```

## Revision to FetchAnndata: pulling data from csr_matrices

```{python}
import numpy as np

varnames = ["CATSPER4", "KLRC1"]

sub_x = r.object[:,["CATSPER4", "KLRC1"]].X

matrix = pd.DataFrame.sparse.from_spmatrix(
          sub_x,
          # csr_matrices don't have row, column names. 
          # These are added here
          index = r.object.obs_names,
          columns = varnames
          )
          
type(matrix["CATSPER4"])

matrix["CATSPER4"] = np.asarray(matrix["CATSPER4"])

for col in matrix:
  print(col)
  print(type(col))
```

